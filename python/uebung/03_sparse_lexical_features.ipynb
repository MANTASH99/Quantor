{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b84c6e6-8d11-460e-8dc5-cd839e7b2dc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lexikalische Merkmale als Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe09721-fc24-43b2-b0c7-d26a7bdf3a13",
   "metadata": {},
   "source": [
    "In den meisten computerlinguistischen Anwendungen des maschinellen Lernens spielen lexikalische Merkmale (wie z.B. die Bag-of-words-Repräsentation von Texten) eine wichtige Rolle. Dabei entsteht oft eine sehr große, aber dünn besetze Mermalsmatrix (engl. **Sparse Matrix**), die über eine Milliarde Werte enthalten kann, von denen jedoch nur ein kleiner Prozentsatz von null verschieden (_nonzero_) ist. Die Verarbeitung solcher Merkmalsmatrizen ist nur mit speziellen, effizienten Speicherformaten praktikabel, die vom **SciPy**-Paket zur Verfügung gestellt werden. Dort finden sich auch zusätzliche Algorithmen aus der linearen Algebra für NumPy-Matrizen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c4fd919-b8ec-48f0-92cf-956bcc617859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85430329-4e24-4cce-aa04-bae65c34109f",
   "metadata": {},
   "source": [
    "Als Beispieldaten ziehen wir ein kurzes, sehr [bekanntes Gedicht](https://www.lyrikline.org/de/gedichte/ottos-mops-1232) heran, dessen Zeilen wir durch lexikalische und textstatistische Merkmale beschreiben wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa1439a-a93b-4520-af6c-b37b5d1fd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ottos_mops = \"\"\"\n",
    "ottos mops trotzt\n",
    "otto: fort mops fort\n",
    "ottos mops hopst fort\n",
    "otto: soso\n",
    "\n",
    "otto holt koks\n",
    "otto holt obst\n",
    "otto horcht\n",
    "otto: mops mops\n",
    "otto hofft\n",
    "\n",
    "ottos mops klopft\n",
    "otto: komm mops komm\n",
    "ottos mops kommt\n",
    "ottos mops kotzt\n",
    "otto: ogottogott\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257ec22-f108-45b7-a162-ec178f9fc581",
   "metadata": {},
   "source": [
    "Die Vorverarbeitung und Tokenisierung dieses Texts gestaltet sich sehr einfach, da alle Token durch Leerzeichen und gelegentlich einen Doppelpunkt begrenzt sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a55f74-76e2-4f0c-9e13-b62ce243c5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ottos', 'mops', 'trotzt'],\n",
       " ['otto', 'fort', 'mops', 'fort'],\n",
       " ['ottos', 'mops', 'hopst', 'fort'],\n",
       " ['otto', 'soso'],\n",
       " ['otto', 'holt', 'koks'],\n",
       " ['otto', 'holt', 'obst'],\n",
       " ['otto', 'horcht'],\n",
       " ['otto', 'mops', 'mops'],\n",
       " ['otto', 'hofft'],\n",
       " ['ottos', 'mops', 'klopft'],\n",
       " ['otto', 'komm', 'mops', 'komm'],\n",
       " ['ottos', 'mops', 'kommt'],\n",
       " ['ottos', 'mops', 'kotzt'],\n",
       " ['otto', 'ogottogott']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [re.split(r':?\\s+', x) for x in ottos_mops.splitlines() if x != \"\"]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acf2530-4155-40c6-8cb3-e581dd991793",
   "metadata": {},
   "source": [
    "## Bag-of-words als Sparse Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04007ac4-3902-473d-a2c5-7fb52bb7c288",
   "metadata": {},
   "source": [
    "Wir erstellen die Sparse-Matrix-Darstellung eines Bag-of-words (**BOW**) zunächst manuell, hier am Beispiel von drei ausgewählten Gedichtzeilen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c64b31-f058-41d0-b3ad-24219a5df016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['otto', 'mops', 'mops'],\n",
       " ['otto', 'komm', 'mops', 'komm'],\n",
       " ['ottos', 'mops', 'kommt']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[corpus[i] for i in (7, 10, 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b505cb-3749-4692-85e6-3d4284e59086",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dazu müssen die Wort-Typen auf die Spalten der BOW-Matrix abbilden; die Zeilen der Matrix entsprechen einfach den drei Gedichtzeilen. Wir benötigen also ein Lexikon, das jedem Typ einen Spaltenindex als numerische ID zuweist, z.B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b284e295-e3cf-4fee-8dc2-7196b97d67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {'otto': 0, 'ottos': 1, 'mops': 2, 'komm': 3, 'kommt': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dac2ed-ca5d-4c64-94df-e3c073e6a79a",
   "metadata": {},
   "source": [
    "Eine Sparse Matrix speichert nur diejenigen Einträge, die von null verschieden sind.  Üblicherweise handelt es sich dabei um nichtnegative Matrizen (was aber nicht notwendigerweise der Fall sein muss).  Zur Erstellung einer solchen Sparse Matrix müssen wir die Positionen aller von null verschiedenen Elemente sowie die zugehörigen Werte angeben.\n",
    "\n",
    "Beispielsweise steht in der zweiten Zeile (`r = 1`) in Spalte `c = lexicon['komm']` der Wert 2. Hier erstellen wir die entsprechenden Listen von Hand. In der Übung lernen Sie, wie ein solcher BOW mit Python-Code erzeugt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e98232-2623-4d34-a95c-de0a68ac37c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 1, 1, 1, 2, 2, 2],\n",
       " ['otto', 'mops', 'otto', 'mops', 'komm', 'ottos', 'mops', 'kommt'],\n",
       " [0, 2, 0, 2, 3, 1, 2, 4],\n",
       " [1, 2, 1, 1, 2, 1, 1, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [0,      0,      1,      1,      1,      2,       2,      2]  # in echtem Code mit effizienterem np.array!\n",
    "w = ['otto', 'mops', 'otto', 'mops', 'komm', 'ottos', 'mops', 'kommt']\n",
    "c = [lexicon[x] for x in w]\n",
    "f = [1,      2,      1,      1,      2,      1,       1,      1]\n",
    "[r, w, c, f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889549c-64bc-4a59-8db6-617177e2d826",
   "metadata": {
    "tags": []
   },
   "source": [
    "SciPy unterstützt verschiedene Sparse-Matrix-Formate. Wir wählen hier das _**coo**ordinate format_, das den von uns erstellten Tripeln enstpricht. Wir können mit `dtype` den Datentyp der gespeicherten Werte festlegen; ohne die Angabe würde aus `f` ein Integer-Format abgeleitet. (**NB:** SciPy stellt die Schnittstelle gerade auf Sparse Arrays um, die besser mit NumPy-Arrays kompatibel sind. Sparse Arrays sindaber noch nicht vollständig implementiert und nur in allerneusten SciPy-Versionen enthalten.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa99a051-547f-41db-9ede-6849e52865e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = sp.sparse.coo_matrix((f, (r, c)), dtype=np.float64)\n",
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7871b6-c7a8-4ae0-91c8-2b0c385ec71d",
   "metadata": {},
   "source": [
    "Zur Ausgabe in der normalen Matrix-Darstellung müssen wir die Sparse Matrix in ein reguläres (dicht besetztes) NumPy-Array umwandeln. In realen Anwendungen soll eine solche Konvertierung natürlich unbedingt vermieden werden und würde oft den verfügbaren Arbeitsspeicher sprengen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bc391a5-fc66-46b9-b783-8f5cf33e0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 2. 0. 0.]\n",
      " [1. 0. 1. 2. 0.]\n",
      " [0. 1. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(M.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd590dc4-4d2a-4e28-87f8-b91f0fc44771",
   "metadata": {},
   "source": [
    "Intern sind nur die von Null verschiedenen Werte als Tripel (_Zeile_, _Spalte_, _Wert_) abgespeichert. Diese Darstellung wird von `print()` ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ffd998-2f58-4ad7-b2d6-1909bc04fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 2)\t2.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (1, 3)\t2.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 4)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ffc33-1950-47d7-a7fc-0c96e6cb7055",
   "metadata": {},
   "source": [
    "Für die weitere Verarbeitung wird die Sparse Matrix meist in einem noch kompakteren Format gespeichert (**csr** = _row-compressed_ oder **csc** = _column-compressed_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2a3af11-dbbc-46e3-a7ab-696de8a7faa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1 = M.tocsr()\n",
    "M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f53ec1-f30e-4dd0-a010-05067f5d4a82",
   "metadata": {},
   "source": [
    "`print()` gibt auch in diesem Fall die Tripel-Darstellung aus. Können Sie aus den drei internen Datenfeldern ableiten, wie das CSC-Format aufgebaut ist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6556b6c7-0c74-45f8-9f98-c6c7f355b591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 2, 5, 8], dtype=int32),\n",
       " array([0, 2, 0, 2, 3, 1, 2, 4], dtype=int32),\n",
       " array([1., 2., 1., 1., 2., 1., 1., 1.])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[M1.indptr, M1.indices, M1.data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9723f-7f00-460b-9f78-ebed4c3d6c17",
   "metadata": {},
   "source": [
    "## Bag-of-words mit Scikit-Learn erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1b93f4-3b8b-4325-95e9-22ea46715a90",
   "metadata": {},
   "source": [
    "In realen Anwendungen erstellen wir den Bag-of-words natürlich nicht selbst, sondern verwenden den optimierten (und recht flexiblen) `CountVectorizer` von **Scikit-Learn**.  Da unsere Texte (d.h. die Gedichtzeilen) bereits als Listen von Token abgespeichert, müssen wir den eingebauten Tokenizer überspringen; stattdessen gibt unsere Identitätsfunktion einfach die vortokenisierte Zeile zurück.\n",
    "\n",
    "**NB:** Da unsere „Texte“ in `corpus` keine Zeichenketten sondern Listen von Token sind, müssen wir auch `lowercase=False` angeben (was passiert sonst?). Alternativ könnten wir auch alle Vorverarbeitungsschritte mit `analyzer=lambda x: x` überspringen. Dann hätten wir aber keine Möglichkeit mehr, auch Bigramme und Trigramme als Merkmale automatisch erstellen zu lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a34e12-590f-4155-9ace-5878117207a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "X_bow = bow.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7628a6-1b15-40bd-a827-857d56994ebd",
   "metadata": {},
   "source": [
    "Der `CountVectorizer` erstellt eine Sparse Matrix im CSR-Format, das für die Repräsentation von Merkmalsvektoren günstig ist (warum?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0847296a-7c3a-4287-9afa-c76d28bc6d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x17 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 38 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac1a37e4-16d2-4031-b24b-1b9ffe745346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1]\n",
      " [2 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 2 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_bow.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4845b80-6c8f-4e54-8cfc-6a30290ce234",
   "metadata": {},
   "source": [
    "Die _features names_ des BOW zeigen uns, welche Spalte welchem Wort-Typ entspricht. Sie sind _nicht_ in der Merkmalsmatrix selbst mit abgespeichert!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba54d0bb-674b-494d-b426-459520363ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fort' 'hofft' 'holt' 'hopst' 'horcht' 'klopft' 'koks' 'komm' 'kommt'\n",
      " 'kotzt' 'mops' 'obst' 'ogottogott' 'otto' 'ottos' 'soso' 'trotzt']\n"
     ]
    }
   ],
   "source": [
    "print(bow.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738774f8-8087-4c5c-a012-34ee5c948512",
   "metadata": {},
   "source": [
    "## Weitere lexikalische Merkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3269f21-0cfb-4014-859c-9052227bbfa7",
   "metadata": {},
   "source": [
    "Neben Bag-of-words-Repräsentationen sind oft auch andere lexikalische Merkmale von Interesse, z.B. Präfix- und Suffix-Zeichenketten beim POS-Tagging. Für die Repräsentation der Gedichtzeilen könnten v.a. Suffix-Zeichenketten relevant sein, da sie auf Reime hindeuten.\n",
    "\n",
    "Da wir für jedes Objekt nur genau einen Suffix einer bestimmten Länge haben können, handelt es sich nicht um einen Bag-of-words, sondern um ein **One-hot-encoding**. Dieses lässt sich in Scikit-Learn mit dem `DictVectorizer` erstellen, der One-hot-encodings für beliebig viele Merkmale gleichzeitig erzeugt. (**NB:** Lesen Sie immer auch die [zugehörige Dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html), um sich mit den Feinheiten der Scikit-Learn-Funktionen vertraut zu machen!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f9d4f2c-edf2-4ac5-862a-79ec9c57b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'suff1': 't', 'suff2': 'zt'},\n",
       " {'suff1': 't', 'suff2': 'rt'},\n",
       " {'suff1': 't', 'suff2': 'rt'},\n",
       " {'suff1': 'o', 'suff2': 'so'},\n",
       " {'suff1': 's', 'suff2': 'ks'},\n",
       " {'suff1': 't', 'suff2': 'st'},\n",
       " {'suff1': 't', 'suff2': 'ht'},\n",
       " {'suff1': 's', 'suff2': 'ps'},\n",
       " {'suff1': 't', 'suff2': 'ft'},\n",
       " {'suff1': 't', 'suff2': 'ft'},\n",
       " {'suff1': 'm', 'suff2': 'mm'},\n",
       " {'suff1': 't', 'suff2': 'mt'},\n",
       " {'suff1': 't', 'suff2': 'zt'},\n",
       " {'suff1': 't', 'suff2': 'tt'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_suffix(line):\n",
    "    s = \" \".join(line)\n",
    "    return {'suff1': s[-1:], 'suff2': s[-2:]}\n",
    "[get_suffix(x) for x in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64516bd1-f7b4-4594-87bf-38a4774a9a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x15 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suff = DictVectorizer(dtype=np.int64) # analog zum BOW-Format\n",
    "X_suff = suff.fit_transform(get_suffix(x) for x in corpus)\n",
    "X_suff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bdd9d31-3884-4b9b-99f3-d1c09496c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_suff.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b093a24-059a-4a18-a965-3e6692161a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['suff1=m' 'suff1=o' 'suff1=s' 'suff1=t' 'suff2=ft' 'suff2=ht' 'suff2=ks'\n",
      " 'suff2=mm' 'suff2=mt' 'suff2=ps' 'suff2=rt' 'suff2=so' 'suff2=st'\n",
      " 'suff2=tt' 'suff2=zt']\n"
     ]
    }
   ],
   "source": [
    "print(suff.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed388e6b-3b51-4af1-ab00-841496b37deb",
   "metadata": {},
   "source": [
    "## Kombination mit numerischen Merkmalen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327df346-e5e7-4d05-9b13-2f96344cf9e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "In vielen Fällen interessieren uns neben dem Bag-of-words und anderen dünn besetzten Merkmalen auch numerische Eigenschaften wie etwas textstatistische Maße. Als Beispiele berechnen wir hier für jede Gedichtzeile ihre **Länge** (= Anzahl Token) und die **durchschnittliche Wortlänge** in der Zeile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ffdb88-ebe2-4049-9bf3-c7773db151aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tok = [len(x) for x in corpus]\n",
    "avg_char = lambda line: sum(len(x) for x in line) / len(line)\n",
    "n_char = [avg_char(x) for x in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb70f0df-e64f-49dc-a7f7-a305557423c3",
   "metadata": {},
   "source": [
    "Wir fügen diese Werte in eine numerische, dicht besetzte Merkmalsmatrix als NumPy-Array zusammen (welchen Trick verwenden wir, um das in einer einzigen Codezeile zu erreichen?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3abdc62-8b12-449a-ac3a-664449db8409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.   5.  ]\n",
      " [4.   4.  ]\n",
      " [4.   4.5 ]\n",
      " [2.   4.  ]\n",
      " [3.   4.  ]\n",
      " [3.   4.  ]\n",
      " [2.   5.  ]\n",
      " [3.   4.  ]\n",
      " [2.   4.5 ]\n",
      " [3.   5.  ]\n",
      " [4.   4.  ]\n",
      " [3.   4.67]\n",
      " [3.   4.67]\n",
      " [2.   7.  ]]\n"
     ]
    }
   ],
   "source": [
    "X_stats = np.vstack([n_tok, n_char]).T\n",
    "print(X_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f0e6a-a855-4e71-b6b9-f1e552e4ca7c",
   "metadata": {},
   "source": [
    "Für die Anwendung maschineller Lernverfahren müssen wir nun noch beide Gruppen von Merkmalen in eine gemeinsame Matrix kombinieren. Das geht grundsätzlich leicht mit `hstack()`, aber dünn und dicht besetze Matrizen können dabei nicht gemischt werden. Es wäre auch kontraproduktiv, dadurch `X_bow` in eine dicht besetzte Matrix umzuwandeln.\n",
    "\n",
    "Stattdessen benötigen wir die Sparse-Matrix-Version von `hstack()` aus dem SciPy-Paket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d89527dc-1e43-49ea-8610-30c2ce478f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x19 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 66 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sp.sparse.hstack([X_bow, X_stats])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67719ed5-637a-4efb-ba68-7eb00c70bcff",
   "metadata": {},
   "source": [
    "Beachten Sie, dass `X_bow` automatisch von einem ganzzahligen Format in eine Gleitkommaformat umgewandelt wurde, um mit den Gleitkommawerten in `X_stats` kompatibel zu sein. Wir überprüfen kurz, dass die Merkmale korrekt zusammengeführt wurden (die Rundung dient zur übersichtlichen Darstellung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67cb60d7-dba2-4ffe-8ca9-b563f2a4fc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 3. 5.]\n",
      " [2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 4. 4.]\n",
      " [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 4. 4.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 2. 4.]\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 3. 4.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 3. 4.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 5.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 0. 3. 4.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 4.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 3. 5.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 1. 0. 0. 1. 0. 0. 0. 4. 4.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 3. 5.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 3. 5.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 2. 7.]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3432d8f-d6f6-4f47-ae37-8c657004aa7f",
   "metadata": {},
   "source": [
    "Auf die gleiche Weise können wir alle drei Merkmalsgruppen (BOW der Wortformen, One-hot-encoding der Zeilensuffixe und numerische Merkmale) in eine vollständige Merkmalsmatrix kombinieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49acac75-b5f9-45e6-99cb-0a9775798f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<14x34 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 94 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = sp.sparse.hstack([X_bow, X_suff, X_stats])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8c03a-b796-4bac-a4b0-f2ae8893d807",
   "metadata": {},
   "source": [
    "Wir führen diese Schritte in der folgenden **Übung** mit einem wesentlich größeren Datensatz für eine realistische Anwendung durch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
