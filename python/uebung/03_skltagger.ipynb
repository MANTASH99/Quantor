{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e990edf-7023-4ad6-add0-110a176cf5ce",
   "metadata": {},
   "source": [
    "# Scikit-Learn-Tagger (SKLTagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91fdc1c-8aaa-40da-8c84-cba6ac5a254a",
   "metadata": {},
   "source": [
    "Da unser Tagger mittlerweile recht komplex geworden ist, modularisieren wir ihn und implementieren die wesentlichen Bestandteile in einem lokalen Paket `skltagger`. Dadurch bleibt das Notebook für unsere Experimente übersichtlich und neue Merkmale können leicht eingebaut werden. Außerdem können wir so später auch leicht eine Kommandozeilenversion oder eine Python-Schnittstelle entwickeln."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49861df-5320-4b1c-a5a2-e0421c0913b2",
   "metadata": {},
   "source": [
    "Zumindest in der Entwicklungsphase werden wir oft neue Versionen z.B. der Merkmalsextraktion importieren wollen, ohne das Notebook komplett neu starten zu müssen. Das ist mit der `%autoreload`-Direktive möglich, die wir hier nur verwenden, um unsere eigenen Module neu zu laden. Ein Re-Import von Pandas, NumPy und SciPy in jeder Programmzelle könnte sonst die Ausführung drastisch verlangsamen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f9fa1-f764-4f76-8b6d-8d95450ab7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport skltagger.vectorizer\n",
    "%aimport skltagger.classifier\n",
    "%aimport skltagger.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3aa2f9-b374-4d61-855b-82580da2b8a1",
   "metadata": {},
   "source": [
    "Bei aktuellen Versionen von IPython/Jupyter sollte `%autoreload` auch mit `from ... import` funktionieren. Im Zweifelsfall ist es aber sicherer, alle Klassen und Hilfsfunktionen mit vollständig qualifizierten Pfaden aufzurufen (z.B. `skltagger.vectorizer.TaggerFeatures()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0881d-46f5-497b-9936-7a617e720377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skltagger.vectorizer import TaggerFeatures\n",
    "from skltagger.classifier import PseudoMarkovClassifier\n",
    "from skltagger.utils import sentences2dataframe, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a761-1436-485a-9b2b-eeb2060f4798",
   "metadata": {},
   "source": [
    "## Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af298cb1-95f6-413b-8c57-b333018bdc0c",
   "metadata": {},
   "source": [
    "Laden und Vorverarbeitung der Trainings- (`_train`) und Testdaten (`_dev`) erfolgt wie gewohnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"sent\", \"tok\", \"word\", \"pos\", \"lemma\", \"morph\")\n",
    "train = pd.read_csv(\"data/tiger2_train.tsv.gz\", sep=\"\\t\", names=header, quoting=3, keep_default_na=False)\n",
    "test = pd.read_csv(\"data/tiger2_dev.tsv.gz\",sep=\"\\t\",names=header, quoting=3, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be37c5-24c1-40d4-8de8-d1420a85be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 0:4]\n",
    "test = test.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e11dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.word = train.word.astype('string')\n",
    "train.pos  = train.pos.astype('string')\n",
    "test.word  = test.word.astype('string')\n",
    "test.pos   = test.pos.astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367edb-80ba-42fd-9b81-76916c759a82",
   "metadata": {},
   "source": [
    "## Verwendung der SKLTagger-Bibliothek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddd2a5-ecba-4f0c-824a-18fd11ede325",
   "metadata": {},
   "source": [
    "Wir haben die Merkmalsextraktion als Klasse mit Scikit-Learn-API implementiert und können sie dadurch in der gewohnten Weise verwenden. Größter Vorteil ist, dass unsere Klasse problemlos in Pipelines integriert werden kann (z.B. für Grid Search).\n",
    "\n",
    "Training und Evaluation eines Taggers ist jetzt sehr übersichtlich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee02af7-df3e-45ee-826e-0e352162c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TaggerFeatures(shape_features=True)\n",
    "X_train = vectorizer.fit_transform(train)\n",
    "X_test = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848c491-d509-4f69-a7fb-783e96f426e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90023e40-4a48-42c9-aa4c-bb0b2c02ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, train.pos)\n",
    "clf.score(X_train, train.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becff2e9-cfc6-4774-b166-21a029e77e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(X_test)\n",
    "print(accuracy_score(test.pos, predicted))\n",
    "print(classification_report(test.pos, predicted, digits=3, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380603c-c958-48cc-a4df-2062acc8270a",
   "metadata": {},
   "source": [
    "Wir können die Merkmalsextraktion auch in eine **Pipeline** integrieren, die dann bereits einen vollständigen POS-Tagger bildet und als Parameterdatei abgespeichert werden kann. Die Evaluation des Taggers auf den Trainings- und Testdaten ist jetzt natürlich deutlich langsamer, da die Merkmalsextraktion jedes Mal erneut durchgeführt werden muss.\n",
    "\n",
    "Wir verwenden dazu Stochastic Gradient Descent als Lernverfahren, das dank Parallelisierung wesentlich schneller trainiert werden kann. Es liefert aber bisweilen etwas schlechtere Ergebnisse als die SVM und ist weniger robust ohne Optimierung der Metaparameter. Wenn wir später Kreuzvalidierung und Grid Search verwenden, relativiert sich der Geschwindigkeitsvorteil ohnehin, so dass die SVM unser bevorzugtes Lernverfahren bleiben dürfte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0051ceb4-a48a-4ce7-9c21-07eea22889ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Pipeline([\n",
    "    ('vect', TaggerFeatures()),\n",
    "    ('clf', SGDClassifier(loss='log_loss', alpha=1e-6, max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "%time tagger.fit(train, train.pos)\n",
    "%time tagger.score(train, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e90fa-da9c-4ecb-b935-c51fe40022ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Aufgabe:** Wie schnell ist der Tagger auf Ihrem Rechner? D.h. wie viele Token / s werden verarbeitet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4db1b-0f62-4bec-936f-9c459631a36d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time tagger.score(test, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad02099e-77f2-4954-acd1-b46a6efcb1cc",
   "metadata": {},
   "source": [
    "Um den Tagger nicht nur auf das Testkorpus, sondern auch beliebige **andere Texte** anwenden zu können, müssen wir diese in unser Pandas-Format überführen. Wir haben dazu eine Hilfsfunktion definiert, die eine Liste von tokenisierten Sätzen transformiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268898f3-e617-40ec-a13d-4edb34c2517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Hunde , die schlafen , bellen nicht !\".split(),\n",
    "    \"Peter streichelt die Hunde .\".split()\n",
    "]\n",
    "print(text)\n",
    "text = sentences2dataframe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c7dbd-88bb-48f4-8e9a-7a88f3b0d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text['pos'] = tagger.predict(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a166-fe83-4343-a3d0-eaf049506165",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kreuzvalidierung und Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85745e-b7b8-4405-b225-a00abc01ab71",
   "metadata": {},
   "source": [
    "Pipelines sind eine Voraussetzung für die saubere Kreuzvalidierung des Taggers, da auch die Merkmalsextraktion jeweils nur auf der als Trainingsdaten ausgewählten Teilmenge trainiert werden darf. Diese Kreuzvalidierung wird wiederum für die Optimierung der Metaparameter gebraucht (bzw. ersetzt dort ein separates Validation Set).\n",
    "\n",
    "Da jede Fold aus vollständigen Sätzen bestehen soll, können wir nicht die Standardaufteilung verwenden sondern benötigen ein `GroupKFold`-Objekt. Dabei stellt jeder Satz eine eigene Gruppe (repräsentiert durch die Satznummer) dar. Die Warnmeldungen bei `cross_validate` lassen sich leider nicht vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdcb9e-f8e2-41f5-bb2c-187d076f9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cv = GroupKFold(n_splits=3)\n",
    "cross_validate(tagger, train, train.pos, cv=group_cv, groups=train.sent, \n",
    "               scoring=('accuracy', 'precision_macro', 'recall_macro', 'f1_macro'), \n",
    "               return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb791c-c15f-420c-9ddf-0989eea65266",
   "metadata": {},
   "source": [
    "Mit Hilfe einer Pipeline können wir auch eine Grid search durchführen, mit der sowohl Merkmalsextraktion als auch das maschinelle Lernverfahren zugleich optimiert werden. Da die Anzahl der zu testenden Metaparameterkombinationen aber schnell explodiert, führt man diese Optimierung in der Praxis oft in mehreren Schritten durch, bei denen einige Parameter bereits festgelegt werden, bzw. Wertebereiche (etwa für $\\alpha$) in einem zweiten Durchlauf verfeinert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a6ed9c-5834-470d-bbd1-8e9512e04646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_pipe = Pipeline([\n",
    "    ('vect', TaggerFeatures()),\n",
    "    ('sgd', SGDClassifier(loss='log_loss', max_iter=5000, n_jobs=-1)),\n",
    "])\n",
    "param_grid = {\n",
    "    'vect__left_context': [1, 2],\n",
    "    'vect__right_context': [0, 1],\n",
    "    'vect__shape_features': [True, False],\n",
    "    'sgd__alpha': [1e-5, 1e-6, 1e-7],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(grid_pipe, param_grid, scoring='accuracy', refit='accuracy',\n",
    "                  cv=group_cv, n_jobs=1, verbose=3) # SGD ist bereits parallelisiert\n",
    "gs.fit(train, train.pos, groups=train.sent);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b5cff7-6697-4b7a-8aab-21941c979976",
   "metadata": {
    "tags": []
   },
   "source": [
    "Wir können nun die optimalen Parameter auslesen und das beste Modell (das bereits auf dem kompletten Datensatz trainiert wurde) auf den Testdaten evaluieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c05efe-a988-490c-b069-c8254c5b978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_estimator_.score(test, test.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8d4b1-043e-4d07-88b2-e4313cab69dc",
   "metadata": {},
   "source": [
    "Eine detailliertere Auswertung der Grid Search, um den Einfluss verschiedener Parameter bzw. Parameterkombinationen zu untersuchen, kann am besten mit Pandas durchgeführt werden. So sehen wir z.B., dass Kontextinformation sowohl von der linken als auch der rechten Seite unbedingt notwendig ist, dass aber mehr als ein Token Kontext keine weitere Verbesserung bringt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670278cd-7cfe-4472-915c-e3827b6f029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_info = pd.DataFrame(gs.cv_results_)\n",
    "gs_info.drop(['params', 'std_fit_time', 'std_score_time'] +\n",
    "             [col for col in gs_info.columns if col.startswith('split')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e510b480-d32d-4c68-9e13-2adc58aaee12",
   "metadata": {},
   "source": [
    "## Sequenzmodellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da74a2-a053-4c2f-a72c-873b3e8bc5b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Unser Tagger verwendet zwar Kontextinformation, trifft aber dennoch für jedes Token eine separate Entscheidung und berücksichtigt nicht, ob die zugewiesenen Tags insgesamt eine plausibles Satzmuster ergeben (im Gegensatz z.B. zum HMM-Tagger). Auch kann er, wie wir gerade gesehen haben, keinen größeren Kontext ausnutzen als die beiden unmittelbar angrenzenden Token.\n",
    "\n",
    "Wir haben zuletzt ein Lernverfahren verwendet (SGD als logistische Regression), das nicht nur eine Tagging-Entscheidung trifft, sondern auch eine Wahrscheinlichkeitsverteilung über alle möglichen Tags lieferen kann. Das ermöglicht im Prinzip eine Kombination mit einem N-Gramm-Modell auf Ebene der Tags, so dass mit dem Viterbi-Algorithmus die plausibelste Abfolge von Tags ausgewählt werden kann – wobei unser Lernverfahren $P(t_i | w_i, w_{i-1}, w_{i+1})$ beisteuert und das N-Gramm-Modell $P(t_i | t_{i-1}, t_{i-2})$. Dabei handelt es sich um eine Annäherung an ein HMM-Modell (wegen der kontextabhängigen lexikalischen Wahrscheinlichkeiten werden dessen Unabhängigkeitsannahmen allerdings verletzt). Statistisch valide wäre eine Kombination mit einem _Conditional Random Field_ (CRF) als Sequenzmodell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216f5bc-8382-4a8a-b0f9-16a130d0e31e",
   "metadata": {},
   "source": [
    "Scikit-Learn bietet leider weder HMM- noch CRF-Modelle an, da [diese nicht zur Scikit-Learn-API passen](https://scikit-learn.org/stable/faq.html#adding-graphical-models) würden. Wir behelfen uns daher mit einer Approximation, die analog zum HMM die Wahrscheinlichkeiten von Tag-N-Grammen lernen kann, aber immer noch eine unabhängige Entscheidung für jedes Token trifft. Wir implementieren diesen Ansatz als eine zweite Lernebene, die als Merkmale Wahrscheinlichkeitsverteilungen $P(t_i | w_i, w_{i-1}, w_{i+1})$ über POS-Tags verwendet, die von unserem bisherigen Lernmodel erstellt werden. Die Verteilung für das aktuell zu taggende Token wird dann mit den Verteilungen der umliegenden Token kombiniert, so dass das Lernverfahren einen Tag wählen kann, der sowohl zur lexikalischen Information als auch zu wahrscheinlichen POS-Tags der umliegenden Token passt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381fc75-f1b5-45f7-8b31-3242b4c94ed3",
   "metadata": {},
   "source": [
    "Als erstes trainieren wir noch einmal einen geeigneten Classifier, der uns die benötigten Wahrscheinlichkeitsverteilungen über alle möglichen Tags liefern kann. Er stellt die erste Stufe unseres Klassifikationsverfahrens dar. Um sinnvolle Wahrscheinlichkeitswerte für die Trainingsdaten zu erhalten, müssen wir die `predict_proba()`-Methode im Rahmen einer Kreuzvalidierung anwenden.\n",
    "\n",
    "**Q:** Warum ist die Kreuzvalidierung hier unbedingt erforderlich? Was würde die zweite Stufe lernen, wenn wir `predict_proba()` ohne Kreuzvalidierung anwenden?\n",
    "\n",
    "An dieser Stelle taucht ein praktisches Problem auf: manche Tags sind so selten, dass sie bei der Kreuzvalidierung möglicherweise im jeweiligen Trainingsdatensatz nicht vorkommen. Aus diesem Grund hätten wir oben auch besser `StratifiedGroupKFold` statt `GroupKFold` verwenden sollen, was hier allerdings nicht weiterhilft (da das Tag `VAIMP` in unseren gesamten Trainingsdaten nur ein einziges Mal vorkommt). Bisher haben wir das Problem einfach ignoriert und die resultierenden Warnungen in Kauf genommen.\n",
    "\n",
    "**Q:** Warum würde die zweite Stufe unseres Klassifikationsverfahren überhaupt nicht mehr funktionieren, wenn wir das Problem weiter ignorieren?\n",
    "\n",
    "Praktikabelste Lösung ist, sehr seltene Tags in den Trainingsdaten zu ersetzen: `VAIMP` duch `VAFIN` und `NNE` (ein Tippfehler) durch `NE`. Wir sollten trotzdem eine stratifizierte Kreuzvalidierung machen, da sonst z.B. `VMPP` (mit $f=4$) in den jeweiligen Trainingsdaten fehlen könnte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2dcc73-fa5d-4e94-b9ac-c1e06320d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_fixed = train.pos.mask(train.pos == 'VAIMP', 'VAFIN').mask(train.pos == 'NNE', 'NE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86f8d2-5729-41e1-a739-23d377957ba3",
   "metadata": {},
   "source": [
    "Der Einfachheit halber führen wir die Merkmalsextraktion direkt auf den gesamten Trainingsdaten aus und wenden die Kreuzvalidierung nur auf den Classifier an. Dadurch können wir auch die voreingestellte Kreuzvalidierung verwenden, die automatisch stratifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0726b8-eddf-4b89-8442-da797b235650",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TaggerFeatures()\n",
    "X = vect.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043daffd-20fe-466d-b634-4700d4ffe8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SGDClassifier(loss='log_loss', alpha=1e-6, max_iter=5000, n_jobs=-1)\n",
    "X_prob = cross_val_predict(clf1, X, train_pos_fixed, cv=2, method='predict_proba')\n",
    "X_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2f662-6880-4754-aef8-0b4a88a030c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1.fit(X, train_pos_fixed); # für Anwendung auf Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f564ecd3-169a-42ff-b6a8-6b0994269cf3",
   "metadata": {},
   "source": [
    "Nun müssen wir die 52-dimensionalen Vektoren mit den Wahrscheinlichkeitsverteilungen über POS-Tags um die entsprechenden Wahrscheinlichkeitsverteilungen für die vorhergehenden und folgenden Token ergänzen. Dazu verschieben wir alle Spalten der Merkmalsmatrix um entsprechend viele Positionen. Theoretisch sollte das ebenfalls satzweise mit Padding geschehen. Um nicht auf die Originaldaten zurückgreifen zu müssen, ignorieren wir die Satzgrenzen und **rotieren** die Spalten (d.h. die untersten Elemente werden oben wieder angefügt und umgekehrt). Diese Operation ist auch direkt in NumPy implementiert, so dass wir nicht auf Pandas oder SciPy ausweichen müssen. Wir definieren dazu eine Hilfsfunktion, da wir sowohl Trainings- als auch Testdaten entsprechend bearbeiten müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22b6f1-d65a-45fe-b10c-91f16795733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contexts(X):\n",
    "    return np.hstack([\n",
    "        X,                      # aktuelles Token\n",
    "        np.roll(X, 1, axis=0),  # erstes Token links\n",
    "        np.roll(X, 2, axis=0),  # zweites Token links\n",
    "        np.roll(X, -1, axis=0), # erstes Token rechts\n",
    "        np.roll(X, -2, axis=0), # zweites Token rechts\n",
    "    ])\n",
    "\n",
    "X_prob = add_contexts(X_prob)\n",
    "X_prob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3090144-1da2-4fdb-83c2-2ff13a412795",
   "metadata": {},
   "source": [
    "Da die zweite Stufe analog zum HMM die Wahrscheinlichkeiten verschiedener POS-N-Gramme lernen soll benötigen wir einen Algorithmus, der Merkmalskombinationen berücksichtigen kann. Beispielsweise wäre eine SVM mit polynomialem Kern grundsätzlich sehr gut geeignet, ist allerdings für unsere großen Trainings- und Testdatensätze viel zu ineffizient. \n",
    "\n",
    "Hier verwenden wir ein Ensemble von Entscheidungsbäumen, das als **Random Forest** bekannt ist. (Freiwillige **Zusatzaufgabe:** Ein alternativer Ansatz besteht darin, einen effizienten linearen Classifier – z.B. SGD – mit einer [Nystroem-Kernelapproximation](https://scikit-learn.org/stable/modules/generated/sklearn.kernel_approximation.Nystroem.html) zu kombinieren. Experimentieren Sie mit diesem Ansatz und unterschiedlichen Parametern der Nystroem-Approximation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0434cb09-ac08-4e02-920e-181ddea1138f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf2 = RandomForestClassifier(n_jobs = -1)\n",
    "clf2.fit(X_prob, train.pos)\n",
    "clf2.score(X_prob, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47cd5ab-c664-4a71-981a-0a0c78a38209",
   "metadata": {},
   "source": [
    "Zur Evaluation des Random-Forest-Classifiers müssen wir für die Testdaten ebenfalls Wahrscheinlichkeitsverteilungen für aktuelles Token und Kontext erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcbeea1-efc8-42e0-a6c8-4c5e30930e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_prob_test = add_contexts(clf1.predict_proba(vect.transform(test)))\n",
    "X_prob_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394e1b8-c90f-46ce-9132-637778fb4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2.score(X_prob_test, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4779aa4-e350-4b9a-84a6-0e877fcfac10",
   "metadata": {},
   "source": [
    "Unser einfacher Ansatz zur Sequenzmodellierung konnte tatsächlich eine merkliche, wenn auch nicht sonderlich große Verbesserung erzielen und die Tagging-Genauigkeit auf knapp 96,8% steigern. Mit optimierten Metaparametern des `RandomForestClassifier` oder zusätzlichem Kontext wäre vielleicht sogar eine weitere Steigerung möglich.\n",
    "\n",
    "**Aufgabe:** Eine Alternative wäre, die Tag-Wahrscheinlichkeiten der Kontext-Token mit der ursprünglichen Merkmalsmatrix zu kombinieren und den zweiten Classifier damit zu trainieren. Da nur lineare Classifier effizient genug mit dieser großen Merkmalsmatrix umgehen, können damit keine N-Gramme von Tags simuliert werden; trotzdem liefern einzelne Tags im Kontext vielleicht nützliche Hinweise zur Desambiguierung. Implementieren Sie diesen Ansatz, wobei der erste Classifier auch einfach die wahrscheinlichsten Tags zuweisen könnte statt die vollen Wahrscheinlichkeitsverteilungen zu berechnen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edffb4df-4be8-436b-b5c5-c58251875799",
   "metadata": {},
   "source": [
    "## Sequenzmodellierung als Pipeline-Komponente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e4d16-4354-43f0-9126-118c58ddac7d",
   "metadata": {},
   "source": [
    "Für weitere Experimente und die praktische Anwendung des Taggers wollen wir unsere zweistufige Approximation der Sequenzmodellierung natürlich als Classifier-Modul in eine Scikit-Learn-Pipeline integrieren. Da eine Pipeline nur einen einzigen Classifier enthalten darf, muss der zweistufige Prozess in ein Modul kombiniert werden.\n",
    "\n",
    "Eine Variante des oben erwähnten alternativen Ansatzes ist in der Klasse `PseudoMarkovClassifier` im Modul `skltagger.classifier` implementiert. Wir verwenden diese Klasse hier, um unseren finalen Tagger zu trainieren und auf den Testdaten zu evaluieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a90b43a-c1bc-4d2c-9a4e-9893d4e4211e",
   "metadata": {},
   "source": [
    "`PseudoMarkovClassifier` verwendet in der ersten Stufe logistische Regression (mit SGD trainiert), um Tag-Wahrscheinlichkeitsverteilungen für die Kontext-Token zu bestimmen. In der zweiten Stufe kann dann ein beliebiger Classifier verwendet werden, der bei der Instanziierung mit übergeben wird. Die Metaparameter dieses Classifiers müssen vorher bereits festgelegt werden und können über das `PseudoMarkovClassifier`-Objekt nicht mehr verändert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78f4e1-89b4-4ded-8fb8-b7e4aabdb32f",
   "metadata": {},
   "source": [
    "Als Beispiel erstellen wir hier eine Pipeline, die die üblichen SKLTagger-Merkmale erstellt und dann unseren zweistufigen Classifier mit einer SVM in der zweiten Stufe anwendet. SVMs haben den Vorteil, dass oft auf ein umfangreiches Tuning der Metaparameter verzichtet werden kann. Wichtige Parameter von `PseudoMarkovClassifier` sind `n_jobs` für Parallelisierung der ersten Stufe sowie die Anzahl der berücksichtigten Kontext-Token. Auch bei relativ großem Kontext entsteht kein hoher Zusatzaufwand, so dass wir hier je 5 Token links und rechts hinzunehmen. (NB: `n_jobs` bezieht sich nur auf die logistische Regression der ersten Stufe und muss ggf. beim Classifier der zweiten Stufe separat angegeben werden. Die vollen Klassenpfade sind notwendig, damit die Serialisierung des trainierten Modells auch bei aktiviertem `autoreload` zuverlässig funktioniert.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fbffd-f19b-4bfb-aa60-c97395896536",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(loss='hinge', C=0.1, max_iter=2000)\n",
    "tagger = Pipeline([\n",
    "    ('vect', skltagger.vectorizer.TaggerFeatures()),\n",
    "    ('pmclf', skltagger.classifier.PseudoMarkovClassifier(svm, left_context=5, right_context=5, n_jobs=-1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea01473-8d95-40fe-b286-93393859ca62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tagger.fit(train, train.pos)\n",
    "tagger.score(train, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c7c26f-24b9-4cbd-9001-7a7231941ba5",
   "metadata": {},
   "source": [
    "**Aufgabe:** Falls Ihnen das Training der SVM zu lange dauert, können Sie stattdessen einen `SGDClassifier` mit `loss='hinge'` einsetzen. Denken Sie daran, hier im Konstruktor auch `n_jobs=-1` anzugeben, damit beide Stufen parallelisiert werden!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cde186-bf68-47bb-a55b-dc8ed412ac91",
   "metadata": {},
   "source": [
    "Die Evaluation auf dem Testkorpus zeigt mit fast **97,3% Genauigkeit** sehr gute Ergebnisse. Der neue Tagger ist zwar deutlich langsamer als das einstufige Verfahren, kann aber immer noch ca. 20k Token / s verarbeiten (_your mileage may vary_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be02040-fac3-4aef-b7e5-e7f605803adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tagger.score(test, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f301a62-24e3-434e-a966-3089cd9d04f3",
   "metadata": {},
   "source": [
    "## Kommandozeilen-Interface\n",
    "\n",
    "Um unseren neuen Tagger praktisch einsetzen zu können, müssen wir das trainierte Modell speichern und später wieder laden können. Wie von der Scikit-Learn-Dokumentation empfohlen setzen wir dafür Funktionen aus dem `joblib`-Paket ein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acac0dbb-e34e-4996-acfa-5b170e32661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(tagger, 'german-tagger.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4696c-d751-4d15-9ff0-1623faad7254",
   "metadata": {},
   "source": [
    "Beim Laden eines Modells sollte überprüft werden, dass es sich tatsächlich um einen SKLTagger handelt. Dazu stellt das `skltagger.utils`-Modul die Funktion `load_model()` bereit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b09a2-44f3-49e6-8884-0636ace03a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model('german-tagger.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092aac60-89d3-41c3-abe6-7e80feba01c9",
   "metadata": {},
   "source": [
    "Schließlich wollen wir ein Kommandozeilen-Interface (_command-line interface_, **CLI**) bereitstellen, mit dem ein trainiertes Tagger-Modell auf Textdateien angewendet werden kann. Es ist üblich (und empfehlenswert), die benötigte Funktionalität in einem separaten Modul (`skltagger.cli`) zu implementieren, so dass sie auch von anderen Python-Programmen genutzt werden kann. Wir verzichten dabei hier auf die eigentlich selbstverständliche ausführliche Dokumentation des Kommandozeilen-Taggers.\n",
    "\n",
    "Der Tagger soll entweder vom Nutzer eingegebene Sätze oder eine ganze Textdatei verarbeiten und muss daher einen geeigneten Tokenizer (hier: SoMaJo) integrieren. Das Tokenizer-Paket muss nur installiert sein, wenn `skltagger.cli` geladen wird. Kern des CLI-Moduls ist eine Funktion, die eine Zeichenkette in Sätze zerlegt, tokenisiert und mit der ebenfalls übergebenen Pipeline taggt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15300e99-fac9-471e-a9e5-56239f2f5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skltagger.cli\n",
    "skltagger.cli.tag_text(tagger, 'Hunde, die schlafen, bellen nicht! Peter streichelt die Hunde.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1a96c-7243-4db0-b67b-c7cd0967e332",
   "metadata": {},
   "source": [
    "Wird das Modul als Skript aufgerufen, dann fungiert es als Kommandozeilen-Programm. Mit der Option `-h` können alle Optionen angezeigt werden:\n",
    "\n",
    "    python -m skltagger.cli -h\n",
    "\n",
    "Als Parameter muss immer die in eine Datei gespeicherte SKLTagger-Pipeline angegeben werden. Ohne weitere Parameter können interaktiv Sätze eingegeben und getaggt werden.\n",
    "\n",
    "    python -m skltagger.cli german-tagger.pkl\n",
    "\n",
    "Es können auch ein oder mehrere Textdateien mit der Option `-i` übergeben werden. Alle Texte werden konkateniert und im _vertical-text_-Format auf STDOUT ausgegeben. Ein typischer Aufruf würde also so aussehen:\n",
    "\n",
    "    python -m skltagger.cli german-tagger.pkl -i text1.txt -i text2.txt -i text3.txt > text.vrt\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
