{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13589679",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6538a4e-f041-4885-b2fe-4cd7e662e4ec",
   "metadata": {},
   "source": [
    "# Einstieg ins maschinelle Lernen\n",
    "\n",
    "## Datensatz: Schwertlilien\n",
    "\n",
    "Für unseren Einstieg ins klassische maschinelle Lernen verwenden wir den **Iris**-Datensatz, den Sie aus der ersten Übung bereits kennen. Zunächst laden wir den Datensatz, der im wesentlichen aus Merkmalsmatrix $\\mathbf{X}$ und Zielvektor $\\mathbf{y}$ besteht. Wie in der Statistik üblich bezeichnen wir die Spalten der Merkmalsmatrix hier auch als **Variablen**, die für jedes Iris-Exemplar den entsprechenden Merkmalswert annehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e5491-7907-49c5-8e31-b318589782a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a062de8-aa7b-4edb-abe4-4d2013984a26",
   "metadata": {},
   "source": [
    "Für überwachtes Lernen müssen wir den Datensatz in Trainings- und Testdaten aufteilen (hier je 50%). Ein Development-Set ist nicht erforderlich, da wir die Optimierung der Metaparameter später per Kreuzvalidierung vornehmen (via `GridSearchCV`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b45c2-1472-45c6-8151-82dd352f7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53502359-c938-45a7-9055-54747b308930",
   "metadata": {},
   "source": [
    "Wir überprüfen, dass der Datensatz stratifiziert aufgeteilt wurde, so dass in jedem Set genau 25 Exemplare jeder Iris-Art enthalten sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9bc63b-572d-4243-9aeb-74801a982991",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([\n",
    "    pd.Series(y_train).value_counts(), \n",
    "    pd.Series(y_test).value_counts()\n",
    "], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf14075-b8d7-49b3-b82d-af5d271ed2e9",
   "metadata": {},
   "source": [
    "> **Frage:** Warum ist es sinnvoll, die Merkmalsvektoren wie in der ersten Übung zu standardisieren? Was passiert bei der Standardisierung genau? (Tipp: Denken Sie an Regularisierungsfunktionen.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfb5c35-9c6c-430e-bfad-115da39264cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c08a81d-ca2f-4d3d-a7d2-68172d51f208",
   "metadata": {},
   "source": [
    "Als scikit-learn-Expert:innen bauen wir die Standardisierung natürlich in eine `Pipeline` ein, statt die Merkmalsmatrix vorab zu modifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5d5cc-4bb3-48c8-8eaf-38d1163bc67f",
   "metadata": {},
   "source": [
    "## Lineare Klassifikation\n",
    "\n",
    "Wir trainieren und evaluieren nun einen lineares Klassifikator.  Als Standardverfahren bietet sich **Logistic Regression** an, die wir in einigen Wochen auch selbst mit Hilfe von NumPy implementieren werden. Im Gegensatz zu unserer eigenen Implementierung unterstützt Scikit-Learn auch multinomiale Klassifikationsprobleme mit mehr als zwei Kategorien.\n",
    "\n",
    "Wir erstellen eine Pipeline mit zwei Komponenten: Standardisierung (`StandardScaler`) und Klassifikation (`LogisticRegression`). Eine Komponente zur Merkmalsextraktion benötigen wir nicht, da als Eingabe ja schon eine numerische Merkmalsmatrix vorliegt. Die Metaparameter der Verfahren belassen wir zunächst bei den voreingestellten Werten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99bb1f-7ec0-4600-8af0-6802f9ddf477",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('std', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50787289-2622-418c-9faa-e1d053df0ffd",
   "metadata": {},
   "source": [
    "Nun können wir die Pipeline trainieren und die erreichte Genauigkeit auf den Trainingsdaten überprüfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af1b49-f008-4332-9295-85f79dbb7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ee7cb-ee61-449c-9d3b-13a258bba8a9",
   "metadata": {},
   "source": [
    "Wie erwartet erzielt das Klassifikationsverfahren auf dem kleinen Trainingsdatensatz fast perfekte Ergebnisse: nur 2 von 75 Iris-Exemplaren werden falsch klassifiziert. Interessanter ist natürlich die Evaluation auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68891a3c-9137-4986-adf5-acf347b3eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pipe.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c6cb3-6794-4634-bd7e-082fff86f42a",
   "metadata": {},
   "source": [
    "Offenbar liegt keine starke Überanpassung vor: die Ergebnisse auf den Testdaten sind nur unwesentlich schlechter. _Iris setosa_ wird dabei perfekt erkannt, nur bei der Abgrenzung zwischen _Iris versicolor_ und _Iris virginica_ kommt es zu ingesamt 4 Fehlern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191d28ef-e63c-4f20-a36f-11fee81f2219",
   "metadata": {},
   "source": [
    "> **Frage:** Können Sie das Evaluationsergebnis erklären, wenn Sie sich die Visualisierung aus der ersten Übung anschauen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5ae6f-1cd2-4ab4-af69-65fd06811e37",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7737ee44-c616-47be-a3fa-113af64253d8",
   "metadata": {},
   "source": [
    "Die Parameter eines linearen Klassifikators können intuitiv als **Merkmalsgewichte** interpretiert werden (im Gegensatz zu den meisten komplexeren Lernverfahren, die oft schwer anschaulich zu interpretieren sind). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fcc991-f433-47a7-bf0f-4bac84aae4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = pipe['clf'].coef_\n",
    "b = pipe['clf'].intercept_\n",
    "\n",
    "print(W.round(3))\n",
    "print()\n",
    "print(b.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b521c78f-97f3-4442-849e-6f5bd3a73b93",
   "metadata": {},
   "source": [
    "> **Frage:** Wofür stehen $\\mathbf{W}$ und $\\mathbf{b}$? Ordnen Sie die Merkmalsgewichte den Kategorien und Variablen zu. Können Sie die Gewichte anschaulich interpretieren? (Tipp: schauen Sie sich dazu wieder die Visualisierungen aus der ersten Übung an.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c4ab0-680f-4d79-aee8-d67f67e16e6e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcb258-d129-4953-bce5-515130ff8acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5eafbc46-c722-468c-8795-101164fb07eb",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf927ce-01ca-4766-b032-451171a0a325",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Für gute Lernergebnisse ist es in den allermeisten Fällen wichtig, die Metaparameter der Lernverfahren (und auch der Merkmalsextraktion und anderer Vorverarbeitungsschritte) systematisch zu optimieren. Erinnern Sie sich, wie Sie zu diesem Zweck eine systematische Grid Search durchführen können? Welche Metaparameter könnten hier von Interesse sein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2092123-0df2-4b5b-91f5-3aebacbbc500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "725026fa-8594-4cdb-8e4d-b596e19906cb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09139c56-1772-4d66-9db7-ec4d4c15a2e4",
   "metadata": {},
   "source": [
    "Wir evaluieren das beste Modell noch auf den Testdaten, um zu überprüfen, ob das Tuning tatsächlich zu einer Verbesserung geführt oder nur die Überanpassung erhöht hat. Leider scheint eher letzteres der Fall zu sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfc6ba2-cd14-4c45-8164-87d805f02752",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_tuned = gs.best_estimator_\n",
    "pred_test = pipe_tuned.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f03f4-293d-4ca1-b14d-ae06b61fb078",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Probieren Sie auch andere Klassifikationsverfahren aus (z.B. SVM, SGD, Nearest Neighbour, Decision Tree). Lesen Sie dazu jeweils die Dokumentation der entsprechenden scikit-learn-Klasse unter https://scikit-learn.org/stable/user_guide.html. Wie gut funktionieren diese anderen Lernverfahren? Können Sie deren Parameter auch anschaulich interpretieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a78b3-83ca-4ad9-9d7e-82694e3f840e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "991b983d-2ae9-4319-ae52-b71c9d41b819",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ziffernerkennung\n",
    "\n",
    "## Datensatz: handgeschriebene Ziffern (MNIST)\n",
    "\n",
    "Der MNIST-Datensatz ist ein klassischer (aber ziemlich einfacher) „Benchmark“ der Bildverarbeitung, bei dem es speziell um die Erkennung handgeschriebener Ziffern geht (z.B. für Postleitzahlen oder Überweisungsformulare). Der Datensatz besteht aus je 7.000 Bildern der Ziffern 0, …, 9 und kann leicht mit Hilfe von Scikit-Learn geladen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b23a0a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", as_frame=False)\n",
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf96d48-ae42-47a5-9d50-63a5a0edb4c6",
   "metadata": {},
   "source": [
    "Die Bilder liegen haben ein Format von $28\\times 28$ Pixeln, die aber als „flache“ Vektoren $\\mathbf{x}\\in \\mathbb{R}^{784}$ gespeichert sind. Wenn wir diese Vektoren als $28\\times 28$-Matrix ausgeben, sind die Ziffern erkennbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbba79a-c688-4a4e-a813-755660c29333",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=160)\n",
    "print(mnist.data[7, :].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646804e-a9cf-40a3-b2c6-fef6b203cef6",
   "metadata": {},
   "source": [
    "Die Pixel werden als Graustufenwerte von 0 bis 255 gespeichert. Statt die einzelnen Pixel (als Variablen der Merkmalsvektoren) zu standardisieren, können wir sie auf den ähnlichen Bereich $[0, 1]$ umskalieren. Damit sollten die meisten Lernverfahren gut umgehen können. Tatsächlich führt die ursprüngliche Skalierung zu Problemen mit der Regularisierung einiger Lernverfahren, die dann nur mit sehr unüblichen Regularisierungsparametern gut funktionieren.\n",
    "\n",
    "Die Zielkategorien sind hier als Zeichenketten `'0'` bis `'9'` kodiert. Wir konvertieren sie in ganzzahlige Werte, wie von den multinomialen Klassifikationsverfahren in Scikit-Learn erwartet wird. Da `fetch_openml()` leider keine Kategorienlabel zurückliefert, legen wir diese selbst in der Variablen `cat_names` an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91ff11-304d-4e62-8040-3a33d1ea7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data / 255\n",
    "y = mnist.target.astype('int')\n",
    "cat_names = [str(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08651ccf-949f-432b-b9af-62593a4d00fe",
   "metadata": {},
   "source": [
    "Um einen bessern Eindruck von der Aufgabenstellung zu bekommen, definieren wir eine Hilfsfunktion, die die Merkmalsvektoren als Pixelbilder anzeigt. Grundsätzlich verwenden wir dazu `plt.imgshow()` mit `cmap=\"binary\"` für Schwarzweißbilder. Um mehrere Ziffern in einer Graphik darzustellen, fasst `mk_imagemap()` diese in eine große Matrix zusammen. Als Beispiel zeigen wir die ersten 50 Ziffern aus dem Datensatz an. Auf die zugehörigen Goldstandard-Label können wir ganz offensichtlich verzichten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf8a19-89a7-477a-8fe1-b7bc03e67bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_imagemap(data, nrow, ncol, padding=2):\n",
    "    w, h = data.shape[-2:]\n",
    "    data = data.reshape((-1, w, h))\n",
    "    n = data.shape[0]\n",
    "    image = np.zeros((nrow * h + (nrow - 1) * padding, ncol * w + (ncol - 1) * padding))\n",
    "    y = 0\n",
    "    k = 0\n",
    "    for i in range(nrow):\n",
    "        x = 0\n",
    "        for j in range(ncol):\n",
    "            if k <= n - 1:\n",
    "                image[y:y+h, x:x+w] = data[k]\n",
    "            x += w + padding\n",
    "            k += 1\n",
    "        y += h + padding\n",
    "    return image\n",
    "\n",
    "plt.imshow(mk_imagemap(X.reshape((70000, 28, 28)), 5, 10), cmap=\"binary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e17e0d-5d10-4f42-9f3f-20209018b5e0",
   "metadata": {},
   "source": [
    "Wir teilen den MNIST-Datensatz in 80% Trainingsdaten und 20% Testdaten auf (was aufgrund des großen Gesamtumfangs völlig ausreichend ist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f19c12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a542ee1-fba0-47eb-b035-2c55b92172e2",
   "metadata": {},
   "source": [
    "## Lineare Klassifikation\n",
    "\n",
    "Wir beginnen wieder mit einem einfachen linearen Klassifikationsverfahren. Zur Wahl stehen neben der bisher verwendeten `LogisticRegression` unter anderem auch Support Vector Machines (nur die lineare Variante `LinearSVC` ist effizient genug) und Stochastic Gradient Descent (`SGDClassifier`). Mit letzterem werden wir uns in den nächsten Wochen noch ausführlich beschäftigen, da es eine der zentralen Grundlagen für Deep Learning darstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c088cad-0e74-4858-8ddc-96f04b56f7bb",
   "metadata": {},
   "source": [
    "Beachten Sie, dass die in Scikit-Learn implementierten Lernverfahren die Bilder einfach als „flache“ Merkmalsvektoren verarbeiten und ihre zweidimensionale Struktur nicht ausnutzen können. Das wird erst später mit Hilfe spezieller Deep-Learning-Modelle möglich.\n",
    "\n",
    "Da wir es jetzt mit einer erheblich größeren Menge von Trainingsdaten und höherdimensionalen Merkmalsvektoren zu tun haben, dauert die Parameterschätzung der Lernverfahren (durch Minimierung der Kostenfunktion $J(\\mathbf{w}; T) = L(\\mathbf{w}; T) + \\lambda C(\\mathbf{w})$) wesentlich länger als bisher. Mit der Direktive `%%time` am Anfang der Zelle können wir jeweils benötigte Rechenzeit anzeigen lassen. Für die logistische Regression müssen Sie mit einer Trainingsdauer von deutlich über 1 Minute rechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4faa13-e878-44be-b311-0f14a5b28289",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(C=1, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print(f\"Training accuracy: {clf.score(X_train, y_train):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cca18-9f4f-4a5c-ac8f-e11f25208ffa",
   "metadata": {},
   "source": [
    "Entscheidend ist natürlich wieder die Evaluation auf den Testdaten. Wie üblich verwenden wir hierzu `classification_report()`, um auch Precision und Recall für jede einzelne Kategorie zu bestimmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8844edf-77f6-40a7-9c24-59095ac1b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred_test, digits=4, target_names=cat_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a8721-db6e-4b1b-a056-42fbe7c2bfd5",
   "metadata": {},
   "source": [
    "> **Frage:** Wie beurteilen Sie die Evaluationsergebnisse? Schauen Sie sich insbesondere auch Precision und Recall für die einzelnen Ziffern an. Gibt es hier auffällige Unterschiede? Wenn ja: was könnten die Ursachen dafür sein?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ddac5-acd4-4cad-9ae5-793ee1678a98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54b86d36-8990-4462-956c-95fdb9cd3acb",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Ein besseres Verständnis der Klassifikationsfehler lässt sich oft aus der _confusion matrix_ ableiten. Erstellen Sie eine solche Fehlermatrix für unseren Ziffern-Klassifikator. Können Sie die Matrix mit Hilfe von `ConfusionMatrixDisplay` auch visualisieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f938268-0311-4d18-9c13-46048e2ee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b7bdf9-9756-4e67-8d40-5570586bc561",
   "metadata": {},
   "source": [
    "## Interpretation der Merkmalsgewichte\n",
    "\n",
    "Die Interpretation der Parameter eines linearen Klassifikators als Merkmalsgewichte ist in diesem Fall besonders anschaulich. Es handelt sich nämlich (jeweils pro Kategorie = Ziffer) um Gewichtungen für die einzelnen Pixel der Bilder. Positive Gewichte markieren Pixel, die _für_ die jeweilige Ziffer sprechen; negative Gewichte markieren Pixel, die _gegen_ die Ziffer sprechen (also bei dieser Ziffer meistens nicht schwarz sind). Wir können die Gewichte also auch als $28\\times 28$-Bilder visualisieren, indem wir die Gewichtsvektoren $\\mathbf{w}\\in \\mathbb{R}^{784}$ jeweils in eine quadratische Matrix $\\in \\mathbb{R}^{28\\times 28}$ umformen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8eaab-8de4-4cfe-b374-3beed463916f",
   "metadata": {},
   "source": [
    "Zu diesem Zweck definieren wir eine kleine Hilfsfunktion, die `mk_imagemap()` zur Darstellung der 10 Gewichtsmatrizen nutzt. Entscheidend ist hierbei, den Wertebereich der Pixel so einzustellen, dass ein Gewicht von 0 genau in der Mitte liegt. (**Frage:** Warum ist das wichtig? Wie wird es in unserer Hilfsfunktion sichergestellt?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02099a-caf9-41d7-b72e-d4e888cd0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(W, cmap='bwr', vmax=None):\n",
    "    image = mk_imagemap(W.reshape((-1, 28, 28)), 2, 5)\n",
    "    if vmax is None:\n",
    "        vmax = np.abs(image).max()\n",
    "        print(f\"range: [{-vmax:.2f}, {vmax:.2f}]\")\n",
    "    plt.imshow(image, cmap=cmap, vmin=-vmax, vmax=vmax)\n",
    "\n",
    "plot_weights(clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc02f8ca-4804-4065-9e3a-f3da0870b183",
   "metadata": {},
   "source": [
    "Rot steht hier für positive Gewichte, blaue für negative, weiß für das Gewicht 0 (also Pixel, die vom Klassifikator gar nicht berücksichtigt werden). Der Farbton ist umso intensiver, je größer die Gewichte sind. Da einige Pixel sehr große Merkmalsgewichte erhalten, bleiben die Farbtöne der meisten anderen Pixel relativ schwach. Wir können mit dem Parameter `vmax=` die Darstellungsskala anpassen, um auch die mittelstarken Gewichte deutlicher zu visualisieren. Dann ist allerdings keine Unterscheidung zwischen großen und sehr großen Gewichten mehr möglich. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60ecfa1-8313-426d-92cf-59a9a811f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(clf.coef_, vmax=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fbcdf-460b-4084-883f-d42280d4f61f",
   "metadata": {},
   "source": [
    "Mit etwas Fanatsie sind zumindest in einigen Fällen (z.B. `0`, `2`, `3`, `8`) die groben Formen der Ziffern in rot auszumachen. Negative Gewichte füllen oft Zwischenräume aus und helfen so bei der Abgrenzung von ähnlichen Ziffern. Markant ist dies z.B. bei der `0`, die in der Bildmitte einen leeren Bereich haben muss. Bei einigen anderen Ziffern (u.a. `1`, `4`, `7`) lässt sich kaum eine vertraute Form erkennen. Auch das erklärt sich schnell durch einen Blick auf die Beispielbilder: für diese Ziffern gibt es viele unterschiedliche Schreibweisen und Orientierungen, die alle in einen einzigen Gewichtsvektor kombiniert werden müssen. Grundsätzlich haben daher alle Pixel, die in _irgendeiner_ Variante vorkommen, positive Gewichte; nur Pixel, die in keiner der Varianten auftauchen, haben negative Gewichte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c60ed8-6d73-4bba-9c20-70b44031eae6",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Experimentieren Sie mit der Regularisierungsstärke und anderen Metaparameter, oder probieren Sie andere lineare Klassifikationsverfahren aus. (Da die einzelnen Trainingsdurchläufe recht langwierig sind, verzichten wir auf ein systematisches Tuning der Metaparameter.) Wie gut fallen die Ergebnisse aus? Wie veränderen sich die Pixelgewichte? Es bietet sich an, eine kleine Hilfsfunktion zur Evaluation des trainierten Klassifikators und der Visualisierung der Merkmalsgewichte zu definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59076f50-5dbb-4198-bc9b-20c9974dd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_linclf(clf, on_train=True, confusion=False, plot=True, vmax=None):\n",
    "    if on_train:\n",
    "        print(f\"Training accuracy: {clf.score(X_train, y_train):.4f}\")\n",
    "    pred_test = clf.predict(X_test)\n",
    "    print(classification_report(y_test, pred_test, digits=4, target_names=cat_names))\n",
    "    if confusion:\n",
    "        print(confusion_matrix(y_test, pred_test))\n",
    "    if plot:\n",
    "        plot_weights(clf.coef_, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eda035-0c18-4b83-8838-5815c283c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037d10d-b8b4-401d-8d96-d4dce176cf4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db4d6bd7-53a0-4127-988c-e2c9c90d12d9",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "In der Vorlesung haben wir Stochastic Gradient Descent bereits als ein effizientes Verfahrung zur Parameteroptimierung linearer Klassifikatoren und insbesondere der logistischen Regression kennengelernt. Hier wird die Regularisierungsstärke direkt über den Parameter `alpha` bestimmt (entsprechend unserem $\\lambda$). Die Lernrate wird in der Voreinstellung automatisch angepasst. Mit der Einstellung `n_jobs = -1` können wir das Training über alle verfügbaren CPU-Kerne parallelisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a74572-5173-440b-99d6-fa37b754fc8f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = SGDClassifier(alpha=1e-3, max_iter=5000, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981312b-e137-4d19-bdce-1e9ac06d47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_linclf(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace5594-52c9-42e4-a475-f72e731bf7e9",
   "metadata": {},
   "source": [
    "In kürzerster Zeit erreichen wir so ein Ergebnis, das nur wenig hinter logistischer Regression und SVM zurückbleibt (mit immer noch deutlich über 90% Genauigkeit auf den Testdaten). Die Merkmalsgewichte sind deutlich besser zu interpretieren als bei `LogisticRegression` und lassen die meisten Ziffern gut erkennen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4c793-3f83-4b48-a604-d117d01c1637",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Was passiert, wenn Sie die Regularisierungsstärke $\\alpha$ erhöhen? Wie verändern sich Genauigkeit, Zeitaufwand und Merkmalsgewichte? Was ist, wenn Sie statt $L_2$-Regularisierung eine $L_1$-Regularisierung verwenden (`penalty`)? Versuchen Sie auch manuell die Lernrate $\\eta$ (`eta0`) einzustellen, wofür Sie `learning_rate='constant'` oder `learning_rate='adaptive'` auswählen müssen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56562142-ad64-4ae1-81ef-056a9b27ebcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d49dc6-84a1-4ee8-ac5e-b2576ed961d7",
   "metadata": {},
   "source": [
    "## Nichtlineare Klassifikation\n",
    "\n",
    "Unsere bisherigen Erkenntnisse legen nahe, dass lineare Klassifikationsverfahren für die Ziffernerkennung nur bedingt geeignet sind. Insbesondere können sie verschiedene Schreibvarianten der gleichen Ziffer nicht separat modellieren. Wir wenden uns daher im letzten Abschnitt nichtlinearen Lernverfahren zu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ca7c7-2dd9-49d6-9c0b-6ef53da310dc",
   "metadata": {},
   "source": [
    "Ein Standardverfahren für nichtlineare Klassifikation sind SVM, die sich durch Auswahl eines geeigneten _kernel_ flexibel konfigurieren lassen. In unserem Fall dürften polynomiale Kerne wenig Vorteile bringen – ein kubischer Kern kann z.B. bestenfalls Kombinationen von je drei Pixeln berücksichtigen. Am flexibelsten ist der RBF-Kern, der aber sowohl beim Training als auch bei der Anwendung auf die Testdaten sehr langsam arbeitet.  Führen Sie die nächsten beiden Zellen am besten vor einer Kaffeepause aus …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdcc6b-8fa0-428b-96d8-6084659a18a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rbf = SVC(kernel='rbf', C=1.0)\n",
    "rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022eb10-2a99-4ea1-94e1-be8d976ab9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_linclf(rbf, on_train=False, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74f06e-1d95-4ea1-90f1-6665b3d9081f",
   "metadata": {},
   "source": [
    "Die SVM mit RBF-Kern erzielt erheblich bessere Ergebnisse als die linearen Klassifikationsverfahren und erreicht auch ohne Tuning eine Genauigkeit von nahezu 98%. Allerdings gibt es hier keine interpretierbaren Merkmalsgewichte. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e7a8b-a152-482e-b6dc-6a255c59f57e",
   "metadata": {},
   "source": [
    "Es gibt auch einige andere Klassifikationsverfahren, die nichtlineare Muster lernen können. Dazu gehören Entscheidungsbäume (die aber in jedem Schritt nur einen einzelnen Pixel berücksichtigen können und daher für die Ziffernerkennung eher nicht geeignet sind) und Nearest-Neighbour-Verfahren. Ein `DecisionTreeClassifier` ist schnell trainiert, zeigt aber extreme Überanpassung an die Trainingsdaten und enttäuschende Evaluationsergebnisse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c0943-65dc-4867-928d-d7935a67d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64a61f-2eba-492d-b88e-5ed23c463be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_linclf(dt, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6ba51-ceb3-4457-907c-69b4841013ae",
   "metadata": {},
   "source": [
    "Der gelernte Entscheidungsbaum ist sehr komplex und für Menschen sicher nicht verständlich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cd827-f36b-4acd-8c1d-0a9f465fbfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Insgesamt {} Entscheidungsknoten bei maximaler Tiefe von {} Schritten.\".format(\n",
    "    dt.tree_.node_count, dt.tree_.max_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd3ff07-f68f-46f8-baf3-f47c7350963e",
   "metadata": {},
   "source": [
    "Bei unserem großen Datensatz und einer zufälligen Aufteilung in Trainings- und Testdaten bietet sich ein Nearest-Neighbour-Verfahren an. Es dürfte sehr gute Ergebnisse lieferen, so lange sich zu jedem Bild in den Testdaten eine sehr ähnlich geschrieben Ziffer in den Trainingsdaten findet. Entscheidenen Parameter sind die Anzahl der nächsten Nachbarn, die für die Entscheidung berücksichtigt werden, sowie das zu verwendende Abstandsmaß.\n",
    "\n",
    "Ein Training im eigentlichen Sinn findet nicht statt: es werden leglich sämtliche Trainings-Datenpunkte abgespeichert. Dafür ist die Anwendung auf neue Daten sehr zeitaufwändig, da der Abstand von jedem neuen Merkmalsvektor zu allen Trainingsdaten berechnet werden muss. Insbesondere ist es wichtig, die langwierige und wenig interessante Evaluation auf den Trainingsdaten zu überspringen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc0d6e-6c8f-479e-ab92-ebab966a7b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "nn.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce25a35-72fb-4d88-b8de-9e776fb712b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eval_linclf(nn, on_train=False, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b2a94-df75-4e61-8f35-e93e0b77712c",
   "metadata": {},
   "source": [
    "Auch diese sehr simple Verfahren erzielt deutlich bessere Ergebnisse als die lineare Klassfikation.  Bessere nichtlineare Verfahren werden wir dann später mit speziellen Deep-Learning-Modellen erproben können."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
