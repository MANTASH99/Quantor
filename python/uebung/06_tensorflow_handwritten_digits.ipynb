{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13589679",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, initializers, Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b983d-2ae9-4319-ae52-b71c9d41b819",
   "metadata": {},
   "source": [
    "# Data set and preparation\n",
    "\n",
    "We use the same MNIST data set for handwritten digit recognition as in session #02. The scikit-learn loader function will automatically download the data set and cache it on the local disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b23a0a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")\n",
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08651ccf-949f-432b-b9af-62593a4d00fe",
   "metadata": {},
   "source": [
    "As before, we visualise the $28\\times 28$ images and the corresponding weight matrices by combining them into an image map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf8a19-89a7-477a-8fe1-b7bc03e67bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_imagemap(data, nrow, ncol, padding=2):\n",
    "    w, h = data.shape[-2:]\n",
    "    data = data.reshape((-1, w, h))\n",
    "    n = data.shape[0]\n",
    "    image = np.zeros((nrow * h + (nrow - 1) * padding, ncol * w + (ncol - 1) * padding))\n",
    "    y = 0\n",
    "    k = 0\n",
    "    for i in range(nrow):\n",
    "        x = 0\n",
    "        for j in range(ncol):\n",
    "            if k <= n - 1:\n",
    "                image[y:y+h, x:x+w] = data[k]\n",
    "            x += w + padding\n",
    "            k += 1\n",
    "        y += h + padding\n",
    "    return image\n",
    "\n",
    "plt.imshow(mk_imagemap(mnist.data.to_numpy().reshape((7000, 10, 28, 28)), 5, 10), cmap=\"binary\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646804e-a9cf-40a3-b2c6-fef6b203cef6",
   "metadata": {},
   "source": [
    "Rescale data from range $0\\ldots 255$ to a more reasonable scale $[0, 1]$. The unusual range of the original features tends to throw the regularisation of some machine learning algorithms off balance (which then need very unusual regularisation parameters to work well). We also convert the target categories to numeric codes $0, \\ldots, 9$ (as expected by deep learning frameworks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91ff11-304d-4e62-8040-3a33d1ea7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.data.to_numpy() / 255\n",
    "y = mnist.target.to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e17e0d-5d10-4f42-9f3f-20209018b5e0",
   "metadata": {},
   "source": [
    "Split data set into 20% test data and 80% training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f19c12",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a542ee1-fba0-47eb-b035-2c55b92172e2",
   "metadata": {},
   "source": [
    "# Baseline: traditional machine learning\n",
    "\n",
    "As a baseline, we repeat the experiments with standard machine learning classifiers, comparing linear and non-linear models. Linear classifiers have the advantage that their parameter matrices can be interpreted as pixel weights.\n",
    "\n",
    "Let's start with a standard linear classifier. SVMs are traditionally used as off-the-shelf models because they tend to be robust without too much metaparameter optimisation. However, training takes its time even with the optimised LibLinear, so you might want to skip this cell for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91681",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = LinearSVC(C=1, max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Training accuracy: {:.5f}'.format(clf.score(X_train, y_train)))\n",
    "result = clf.predict(X_test)\n",
    "print(classification_report(y_test, result, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b33b5-c162-4333-939e-96356cf5102f",
   "metadata": {},
   "source": [
    "Stochastic gradient descent is much faster with multicore processing, but very sensitive to regularisation parameter.  With the right choice of $\\alpha$, we can achieve $> 90\\%$ accuracy in just a few seconds of training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b3f31-f71c-46bf-89fe-97d3ca461ffe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = SGDClassifier(alpha=1e-4, max_iter=5000, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Training accuracy: {:.5f}'.format(clf.score(X_train, y_train)))\n",
    "result = clf.predict(X_test)\n",
    "print(classification_report(y_test, result, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1276290-eca8-4346-84ec-61459d5a41ae",
   "metadata": {},
   "source": [
    "An important advantage of linear classifiers for this exercise is that we can easily visualise the feature weights learned by the classifier. Here, we can roughly make out the shapes of the corresponding digits in the plot (or at least some of them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310c713-7bcf-4571-9698-25bada8178a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weights(W, nrow=2, ncol=5, size=28, cmap='bwr', vmax=None):\n",
    "    image = mk_imagemap(W.reshape((-1, size, size)), nrow, ncol)\n",
    "    if vmax is None:\n",
    "        vmax = np.abs(image).max()\n",
    "        print(f\"range: [{-vmax:.2f}, {vmax:.2f}]\")\n",
    "    plt.imshow(image, cmap=cmap, vmin=-vmax, vmax=vmax)\n",
    "\n",
    "plot_weights(clf.coef_, vmax=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ca7c7-2dd9-49d6-9c0b-6ef53da310dc",
   "metadata": {},
   "source": [
    "The classification accuracy is still unsatisfactory, though, and there is no evidence of overtraining, indicating that simple linear classifiers are not flexible enough. An SVM with _rbf_ kernel performs much better in fact, but takes very long to train. Instead, let us try a **nearest neighbours** classifier, which should work quite well given the large amount of training data for each class and the fact that – while there are different “writing styles” for some digits – many exemplars tend to look highly similar.  The result indeed shows a substantial improvement over SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13799a22-d77b-41de-bd44-99873b4bd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nn = KNeighborsClassifier(n_neighbors=10, metric='manhattan')\n",
    "nn.fit(X_train, y_train)\n",
    "result = nn.predict(X_test)\n",
    "print(classification_report(y_test, result, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b752a7-adc5-495d-aca3-2b7e953ec131",
   "metadata": {},
   "source": [
    "# Neural Networks with TensorFlow\n",
    "\n",
    "For some of our deep learning models, the feature vectors need to be reshaped into $28\\times 28$ matrices, so that we can exploit the two-dimensional structure of the images with convolutional layers later on.  The target categories should in principle be converted to one-hot encodings, but TensorFlow accepts integer class codes with sparse categorical cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3fa121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f36af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211f153",
   "metadata": {},
   "source": [
    "Neural networks are defined in TensorFlow by creating layer objects and connecting them via function application, feeding the output of one layer as input argument to the next layer. Our first neural network consists of single fully connected layer with softmax activation function and corresponds to a logistic regression linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68368f68-35a9-4cb5-b3a6-1a38de8aa206",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28))\n",
    "flatten = layers.Flatten() # convert 28x28 image back to feature vector\n",
    "layer1 = layers.Dense(10, activation='softmax', # extra arguments below are useful for visualisation\n",
    "                      kernel_initializer='zeros', kernel_regularizer=regularizers.L1(l1=1e-6))\n",
    "flatten_out = flatten(inputs)\n",
    "layer1_out = layer1(flatten_out)\n",
    "model = Model(inputs=inputs, outputs=layer1_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d02f3",
   "metadata": {},
   "source": [
    "Unlike Scikit-Learn, a neural network model has to be compiled (into a compute graph that can be executed e.g. on a GPU) before it can be trained. In this step, we also specify the loss function (remember that we need _sparse categorical cross-entropy_ for our training data), the parameter optimisation algorithm (here: adaptive SGD with momentum), and the evaluation metric (here: classification accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d23d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd50aae",
   "metadata": {},
   "source": [
    "Now we can train the neural network. Here, we train for a total of 20 epochs, using 256 images in each SGD batch. The `verbose` parameter specifies how much progress information is displayed during training. The `validation_data` parameter allows us to monitor the accuracy on a validation set as an indication of over-training (normally, we should not use the test set but a separate validation set for this purpose, of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb962758",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res = model.fit(X_train, y_train, epochs=30, batch_size=512, verbose=2,\n",
    "                validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345676b1",
   "metadata": {},
   "source": [
    "The final model can easily be evaluated on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a23798",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {100 * test_acc:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f33c23",
   "metadata": {},
   "source": [
    "The predictions made by the model are actually probability distributions over the 10 categories. In order to predict the integer values (category codes), we need to find the most probable category for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64e35a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test, verbose=0)\n",
    "print(np.round(predictions[:10, :], 3))\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9dcba",
   "metadata": {},
   "source": [
    "Verify the evaluation score above using Scikit-Learn evaluation metrics and obtain P/R/F for each digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d75bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab325c7",
   "metadata": {},
   "source": [
    "Training the neural network with the `fit()` method has returned an object `res`, which we can use (amongst other things) to plot learning curves across the training epochs. **NB:** These are not the learning curves we're usually interested in, which show how the amount of training data affects the final accurac (while the training process shown here always uses the full data set).  It is much more time-consuming to produce such “true” learning curves because the training has to be restarted from scratch for each data point to be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276a1db",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(res.history['accuracy'], linewidth=3)\n",
    "plt.plot(res.history['val_accuracy'], linewidth=3)\n",
    "plt.axis(ymin=.8, ymax=1)\n",
    "plt.xlabel(\"# epochs\"); plt.ylabel(\"accuracy\")\n",
    "plt.legend((\"training data\", \"test data\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d4fce",
   "metadata": {},
   "source": [
    "As with linear models in Scikit-Learn, we can read out the feature weights and bias terms for each category and visualise them.  Note that the `layer1` object has been integrated into `model`, but it still encapsulates the trained parameters for this layer.  We could also retrieve weights from `model.layers[2]`, but it's too easy to confuse different layers that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce86e5-eb11-4a6f-91fb-4e9a50b0243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = layer1.get_weights()[0]\n",
    "print(W.shape)\n",
    "b = layer1.get_weights()[1]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefe235-ed8e-4e5e-af08-f154ee8977d9",
   "metadata": {},
   "source": [
    "For visualisation of the learned weights, we need to transpose the weights matrix into the usual $10\\times 784$ format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c69ca-9335-4a57-b71b-efc0dc983386",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(W.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61904a",
   "metadata": {},
   "source": [
    "> **Exercise:** Re-train the neural network with different meta-parameter settings and different numbers of epochs and check how this affects (i) final accuracy, (ii) learning curves and overtraining, and (iii) the feature weights learned by the network (using the visualisation above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdabad3-eeed-4c23-b113-1b287f4857c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e94817b",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "A singe-layer neural network is still a linear classifier (in our case equivalent to a multinomial logistic regression model), so it cannot account for multiple prototypes representing different styles of writing a digit and fails to achieve much better accuracy than a linear SVM or logistic regression with SGD. However, we can much more easily change the neural network to a non-linear classifier by adding a “hidden” layer, which must also have a non-linear activation function.  Even such a two-layer network can learn very complex decision boundaries, depending on the number of neurons in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c5f070",
   "metadata": {},
   "source": [
    "Intuitively, we want the hidden layer to represent distinct styles for each digit (which should easily be learned by a linear classifier), i.e. each neuron should detect one particular digit shape. The second and final layer only has to learn how to map the shapes to digits.  Some digits appear to be fine with a single prototype (e.g. 0 and 3, whose shapes are easily recognised in the visualisation of the weights matrix), while others with very blurry shapes (e.g. 1, 4, 6, 9) may need more than three prototypes.  This intuitive reasoning would suggest between 20 and 30 neurons for the hidden layer, but some experimentation shows that the network learns much better with a larger hidden layer.  Training also takes more epochs than before and we need to allow for some overtraining to achieve optimal test accuracy.\n",
    "\n",
    "The metaparameter settings below are rather uncommon and have been selected to bring out a reasonable visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa0a8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inputs = Input(shape=(28, 28))\n",
    "flatten = layers.Flatten()\n",
    "hidden = layers.Dense(48, activation='sigmoid', kernel_regularizer=regularizers.L1(l1=1e-5))\n",
    "final = layers.Dense(10, activation='softmax', kernel_regularizer=regularizers.L1(l1=1e-4))\n",
    "hidden_out = hidden(flatten(inputs))\n",
    "final_out = final(hidden_out)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=final_out)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# set verbose=1 or verbose=2 below to follow training progress\n",
    "res = model.fit(X_train, y_train, epochs=50, batch_size=256, verbose=0,\n",
    "                validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {100 * test_acc:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b78226",
   "metadata": {},
   "source": [
    "This neural network already outperforms the nearest neighbours classifier!  However, a look at the weights matrix of the output layer (in our displays, rows correspond to output neurons and columns to the first 16 neurons of the hidden layer) shows that our intuition didn't quite work out.  We expected that each neuron of the hidden layer might learn to recognise one particular digit style, so it would ideally map only to the corresponding output neuron (i.e. each column of the matrix displayed belowed should be close to a one-hot vector).  But in fact, most hidden layer neurons contribute to many output neurons with positive _and_ negative weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09cec7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W2 = final.get_weights()[0]\n",
    "print(np.round(W2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee726f",
   "metadata": {},
   "source": [
    "As a result, the feature weights of the hidden layer aren't immediately recognisable as digit styles, though some of the shapes are reminiscent of (parts of) digits, often mixed together in various combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ea55e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W1 = hidden.get_weights()[0].T.reshape(-1, 28, 28)\n",
    "plot_weights(W1, 6, 8, vmax=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc21b12",
   "metadata": {},
   "source": [
    "> **Exercise:** Experiment with different regularisations, layer initialisations and network designs.  Which parameter settings improve classification accuracy?  Do the same settings also result in more recognisable feature weights in the visualisation?  What happen if you increase or decrease the number of neurons in the hidden layer?\n",
    "> \n",
    "> **Exercise:** Experiment with deeper network topologies.  One of the fundamental insights of Deep Learning is that having more layers leads to better and more robust learning results than having more neurons in a single hidden layer.  Is this also the case for handwritten digit recognition, or is the task too simple?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b917e",
   "metadata": {},
   "source": [
    "As we start to experiment more, we will want to re-use code by encapsulating repetitive tasks in subroutines.  We will still have to create the neural networks from scratch as we want to change their topologies in the experiments, but compiling the model, training and evaluation are always the same, so we can wrap them in a support function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2dbc6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_eval(inputs, outputs, epochs=42, batch_size=256, verbose=1, plot=False):\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    res = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "    print(f'Test accuracy: {100 * test_acc:.3f}%')\n",
    "\n",
    "    if plot:\n",
    "        plt.plot(res.history['accuracy'], linewidth=3)\n",
    "        plt.plot(res.history['val_accuracy'], linewidth=3)\n",
    "        plt.axis(ymin=.8, ymax=1)\n",
    "        plt.xlabel(\"# epochs\"); plt.ylabel(\"accuracy\")\n",
    "        plt.legend((\"training data\", \"test data\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94923d32",
   "metadata": {},
   "source": [
    "As an example, here is a neural network with two fairly large hidden layers. Without regularisation, the network learns very quickly and overtrains substantially, but it still achieves better results on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9dec6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inputs = Input(shape=(28, 28))\n",
    "flatten = layers.Flatten()\n",
    "hidden1 = layers.Dense(128, activation='sigmoid')\n",
    "hidden2 = layers.Dense(64, activation='sigmoid')\n",
    "final = layers.Dense(10, activation='softmax')\n",
    "final_out = final(hidden2(hidden1(flatten(inputs))))\n",
    "\n",
    "model = train_and_eval(inputs, final_out, epochs=42, verbose=2, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7e1ac1",
   "metadata": {},
   "source": [
    "It's hard to make much sense of the image maps learned by the first layer, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb191ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "W1 = hidden1.get_weights()[0].T.reshape(-1, 28, 28)\n",
    "plot_weights(W1, 8, 16, vmax=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b3ed3",
   "metadata": {},
   "source": [
    "# Convolutional neural networks (CNN)\n",
    "\n",
    "For image analysis, a huge disadvantage of simple fully-connected layers is that they learn feature weights for each individual pixel of an image rather than to recognise shapes that can appear in different positions.  This is achieved by convolutional layers, which have become a standard approach for image classification tasks.  Here, we try a simple approach with a single convolutional hidden layer, which learns “filters” of size $15\\times 15$ pixels that are swept across the image. A pooling layer reduces these to a lower resolution ($7\\times 7$ positions for the 64 filter channels), which are then fed into a dense final layer.\n",
    "\n",
    "**NB:** Convolutional layers are designed for image analysis and assume that there are multiple colour channels, so for our greyscale image the input is a $28\\times 28\\times 1$ tensor rather than a $28\\times 28$ matrix.  Fortunately, the input layer can make this adjustment automatically if we specify the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2643822f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "cnn = layers.Conv2D(64, (15, 15), activation='relu')\n",
    "z = cnn(inputs) # convolutional layer with 64 filters of 15x15 pixels\n",
    "z = layers.MaxPooling2D((2,2))(z) # reduce resolution by taking maximum over each 2x2 square of filter positions\n",
    "z = layers.Flatten()(z) # flatten the 7x7x1 tensor for final dense layer\n",
    "outputs = layers.Dense(10, activation='softmax')(z)\n",
    "\n",
    "# Compile the model\n",
    "model = train_and_eval(inputs, outputs, epochs=20, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f7a1d",
   "metadata": {},
   "source": [
    "Printing a summary can help us understand what happens in the different layers of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13438b86",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43623036",
   "metadata": {},
   "source": [
    "A visualisation of the convolutional filters suggests that they recognise certain shapes, which could be part of digits, but it's difficult to make them out very clearly.  **Exercise:** perhaps you can find a CNN topology that generates more visually appealing features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae84721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = cnn.get_weights()[0].transpose((2, 3, 0, 1))[0] # weights tensor has shape (15, 15, 1, 64)\n",
    "plot_weights(W1, 8, 8, size=15, vmax=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f76905",
   "metadata": {},
   "source": [
    "> **Exercise:** Can you think of other visualisations that could give us insights into what the CNN has learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcea92",
   "metadata": {},
   "source": [
    "As a last step, let's try a deep network with multiple CNN and dense layers.  It takes a lot of experience to guess which network topologies work best, where to add layers, etc.  You will also need to add some form of regularisation in order to keep very deep networks from overtraining drastically.  A very simple strategy that can work surprisingly well is to simply stop training early, e.g. when validation loss stops decreasing or even starts to increase again.  More advanced strategies will be explored in further sessions of this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28, 28, 1))\n",
    "cnn1 = layers.Conv2D(32, (5, 5), activation='relu')\n",
    "z = cnn1(inputs) # first CNN layer learns small shape fragments of 5x5 pixels\n",
    "cnn2 = layers.Conv2D(64, (9, 9), activation='relu')\n",
    "z = cnn2(z)      # second CNN layer then should recognise larger building blocks\n",
    "z = layers.MaxPooling2D((4, 4))(z) # reduce resolution of these blocks for final dense layers\n",
    "z = layers.Flatten()(z) # flatten the 4x4x1\n",
    "hidden1 = layers.Dense(64, activation='sigmoid')\n",
    "z = hidden1(z)   # hidden layer over the feature map\n",
    "final = layers.Dense(10, activation='softmax')\n",
    "outputs = final(z) # final classification layer\n",
    "\n",
    "# Compile the model\n",
    "model = train_and_eval(inputs, outputs, epochs=20, verbose=2, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d127e",
   "metadata": {},
   "source": [
    "Note how many parameters this model has (more than 230,000), so it should be very prone to overtraining.  Due to the deep topology of the network, we still obtain very good classification accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377f6a02-a3bc-450a-92c1-332007b6b6b6",
   "metadata": {},
   "source": [
    "> **Exercise:** Can you further improve on this model? Does it help to add even more layers? Try reducing overtraining by adding layer regularisation or with the help of `Dropout` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a448ca-22eb-468b-a29e-24e977652402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
