{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e990edf-7023-4ad6-add0-110a176cf5ce",
   "metadata": {},
   "source": [
    "# POS-Tagging mit maschinellen Lernverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35c312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a761-1436-485a-9b2b-eeb2060f4798",
   "metadata": {},
   "source": [
    "## Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af298cb1-95f6-413b-8c57-b333018bdc0c",
   "metadata": {},
   "source": [
    "Trainings (`_train`) und Testdaten (`_dev`) laden. Da die TSV-Tabellen keine Kopfzeile haben, müssen wir sinnvolle Spaltennamen selbst festlegen. Wichtig ist dabei, dass Anführungszeichen als normale Zeichen gelesen (`quoting=3`) und `null`, `N/A` usw. nicht als undefinierte Werte interpretiert werden (sehr unintuitiv mit `keep_default_na=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"sent\", \"tok\", \"word\", \"pos\", \"lemma\", \"morph\")\n",
    "train = pd.read_csv(\"data/tiger2_train.tsv.gz\", sep=\"\\t\", names=header, quoting=3, keep_default_na=False)\n",
    "test = pd.read_csv(\"data/tiger2_dev.tsv.gz\",sep=\"\\t\",names=header, quoting=3, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5436bf-1581-4fc7-b000-24ced338dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32342f4f-7ce6-4d46-81f1-26a205de0d0f",
   "metadata": {},
   "source": [
    "Wir benötigen nur die ersten 4 Spalten (`lemma` und `morph` können wir später für andere Aufgaben nutzen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be37c5-24c1-40d4-8de8-d1420a85be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 0:4]\n",
    "test = test.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f454e68-0b78-4b52-aa8c-ae1b5ad36f3a",
   "metadata": {},
   "source": [
    "Strings werden in Pandas als Arrays vom Typ `object` eingelesen.  Wir können sie explizit in spezielle `StringArray`s konvertieren, die aber [momentan wohl noch keine besonderen Performance-Vorteile](https://pandas.pydata.org/docs/user_guide/text.html) bieten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e11dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.word = train.word.astype('string')\n",
    "train.pos  = train.pos.astype('string')\n",
    "test.word  = test.word.astype('string')\n",
    "test.pos   = test.pos.astype('string')\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367edb-80ba-42fd-9b81-76916c759a82",
   "metadata": {},
   "source": [
    "## Unigramm-Tagger (ohne Kontext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45213690-49fc-45f7-af0e-4c4829043eba",
   "metadata": {},
   "source": [
    "Wir implementieren zunächst einen Unigramm-Tagger, der nur auf Wortformen arbeitet und keine Kontextinformation hinzuzieht. Das lässt sich besonders einfach mit der Pandas-Repräsentation der Trainingsdaten umsetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e9a63-1504-4ae8-a2be-cff05ec40eb9",
   "metadata": {},
   "source": [
    "Das naheliegendste Merkmal sind die Wortformen selbst, für die wir ein Dummy Coding (_one-hot encoding_) erstellen müssen.  Dies lässt sich direkt mit dem `OneHotEncoder` erstellen (oder dem `DictVectorizer`, der aber wesentlich mehr Overhead produziert).  Ein besonders einfacher und flexibler Ansatz ist ein `CountVectorizer`, der jeweils nur ein Token als Eingabe bekommt und viele weitere Optionen anbietet.  Wir vergleichen hier die Verarbeitungsgeschwindigkeit aller drei Varianten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4a6e6-4abe-40e6-85a0-711bc1035fd5",
   "metadata": {},
   "source": [
    "**1) OneHotEncoder:** Erwartet Listen oder Tupeln von Merkmalswerten, die jeweils in ein _one-hot encoding_ überführt werden. Hier müssen wir die Wörter also in Tupel der Länge 1 transformieren. Die Option `handle_unknown` muss auf `'ignore'` gesetzt werden, damit unbekannte Wortformen in den Testdaten keinen Fehler werfen. Mit `min_frequency` und `'infrequent_if_exist'` kann eine OOV-Kodierung implementiert werden. Wir setzen hier eine Schwellenwert von $f \\ge 5$ an, damit nur halbwegs zuverlässige Lexikoninformation gelernt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d2785-1a82-42c3-8efa-0093409d2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_vectorizer = OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=5)\n",
    "%time X_wf = wf_vectorizer.fit_transform([(x,) for x in train.word])\n",
    "%time testX_wf = wf_vectorizer.transform([(x,) for x in test.word])\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff172ac-9edd-479b-8432-9f29356b11ec",
   "metadata": {},
   "source": [
    "**2) DictVectorizer:** Hier stehen keine Optionen zur Auswahl, insbesondere könnte ein Schwellenwert wie $f\\ge 5$ nur als zusätzliche Transformation der Merkmalsmatrix umgesetzt werden. Obwohl als Eingabe eine Liste von Dictionaries erstellt werden muss, ist dieser Ansatz schneller als der OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc75a28-5746-4661-b2c9-2e7a05571d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_vectorizer = DictVectorizer()\n",
    "%time X_wf = wf_vectorizer.fit_transform([{\"word\": x} for x in train.word])\n",
    "%time testX_wf = wf_vectorizer.transform([{\"word\": x} for x in test.word])\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cd44d-102d-419c-a2e5-35b113d383e6",
   "metadata": {},
   "source": [
    "**3) CountVectorizer:** Wir können das _one-hot encoding_ auch mit einem `CountVectorizer` erzeugen, der jede Wortform als ein einzelnes Token behandelt (was durch einen geeigneten Custom-Tokenizer sichergestellt werden muss). Mit `binary=True` könnten wir auch explizit erzwingen, dass eine binäre Matrix erzeugt wird. Der Schwellenwert $f\\ge 5$ lässt sich leicht mit `min_df` anwenden (in der Binärmatrix ist ja $f = \\mathit{df}$); allerdings werden hier die OOV nicht explizit repräsentiert (sondern durch einen $\\mathbf{0}$-Vektor) und müssen implizit von dem maschinellen Lernverfahren gelernt werden. Dieser Ansatz ist zwar etwas langsamer als der `DictVectorizer`, wegen seiner Flexibilität aber vorzuziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef3e43-bf86-414c-8a25-e26e2d7f4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_vectorizer = CountVectorizer(tokenizer=lambda x: (x,), lowercase=False, min_df=5)\n",
    "%time X_wf = wf_vectorizer.fit_transform(train.word)\n",
    "%time testX_wf = wf_vectorizer.transform(test.word)\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acd0c3-46b2-469a-87c0-cfd35c08d92a",
   "metadata": {},
   "source": [
    "Wir können nun ein erstes Lernexperiment mit einer linearen SVM durchführen (ohne Optimierung der Meta-Parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_wf, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92641963-344f-4ec4-8f17-9e3cbf01ff30",
   "metadata": {},
   "source": [
    "Evaluation auf den Testdaten ergibt schon eine ganz passable Genauigkeit. Ein Vergleich mit den Trainingsdaten zeigt, dass die SVM kaum übertrainiert ist (**Frage:** Was könnte der Grund dafür sein?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291ee99-7575-4324-8c7a-aea066e7d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(testX_wf)\n",
    "print(accuracy_score(predicted, test.pos))\n",
    "\n",
    "print(clf.score(X_wf, train.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305bfd9-8298-4a4f-8db1-9173acc18539",
   "metadata": {},
   "source": [
    "### Fehleranalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e882319-f1e8-441f-8ce4-b71e03318faa",
   "metadata": {},
   "source": [
    "Der beste Ausgangspunkt für eine gezielte Optimierung der Lernergebnisse ist oft eine detaillierte Fehleranalyse. Als ersten Schritte berechnen wir Precision und Recall separat für jede Kategorie, d.h. jedes POS-Tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cca51f-6134-46a6-a27e-cf9cd6b7e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test.pos, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113e084-cf68-4f5c-8367-1eb634a3c71d",
   "metadata": {},
   "source": [
    "Schlechte Ergebnisse bei offenen Wortklassen könnten zu einem erheblichen Teil auf unbekannte Wörter zurückzuführen sein, für die immer die gleiche Wortart geraten wird. Bei geschlossenen Wortklassen deuten sie darauf hin, dass Kontextinformation zur Disambiguierung notwendig wäre. So etwa bei `PTKVZ` (abgetrennte Verbpartikel, z.B. _Stephanie geht <u>aus</u>_), die oft auch Präpositionen sein können.\n",
    "\n",
    "Um diese Hypothese näher zu untersuchen, können wir z.B. eine separate Evaluation nur für unbekannte Wörter durchführen. Wir erkennen diese daran, dass ihre Merkmalsvektoren $\\mathbf{0}$ sind. Wir sehen nun, dass alle unbekannten Wörter als `NN` getaggt werden und dass es sich dabei überwiegend um offene Wortklassen handelt (Spalte _support_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4ce49-b247-41bc-9dfc-cd62f7bbc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_oov = testX_wf.sum(axis=1) == 0\n",
    "idx_oov = np.asarray(idx_oov).squeeze() # Spaltenvektor (Typ: np.matrix) in Vektor konvertieren\n",
    "print(classification_report(test.pos[idx_oov], predicted[idx_oov], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a24912-b0ba-4b97-8704-17b8a68a5642",
   "metadata": {},
   "source": [
    "Schließlich können wir noch eine Fehlermatrix (_confusion matrix_) berechnen, die die häufigsten Fehler aufzeigt und schön visualisiert werden kann. Da sich die volle Fehlermatrix nur schwer darstellen lässt, konzentrieren wir uns auf ausgewählte Wortarten, z.B. Substantive, Vollverben, Adjektive und Adverbien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ab3eb-1d3f-4e50-aa11-4c360e471380",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_tags = ('ADJA', 'ADJD', 'ADV', 'NE', 'NN', 'VVFIN', 'VVINF', 'VVIMP')\n",
    "cm = confusion_matrix(test.pos, predicted, labels=focus_tags)\n",
    "ConfusionMatrixDisplay(cm, display_labels=focus_tags).plot(cmap='OrRd');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51523a-018a-4526-a9fb-d87f33c87cca",
   "metadata": {},
   "source": [
    "Auffallend ist eine Spalte, mit zahlreichen Fehlern, bei denen das Lernverfahren `NN` vorhergesagt hat. Hier handelt es sich mutmaßlich zu einem großen Teil um unbekannte Wörter. Im nächsten Schritt gilt es nun also, Wortarten für solche unbekannten Wörter zu erraten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01876d2-80e8-4d94-a23d-701dbdcd42b1",
   "metadata": {},
   "source": [
    "### Präfix- und Suffixmerkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a688a-a0be-410d-9989-b6fecdfcab31",
   "metadata": {},
   "source": [
    "Die Wortart eines unbekannten Wortes lässt sich am ehesten aus der Endung (Suffix der letzten $k$ Zeichen, z.B. _-bares_) erraten, sowie teilweise auch aus dem Wortanfang (z.B. _ge-_). Wie viele Zeichen $k$ zu berücksichtigen sind, kann nur empirisch durch Experimente mit verschiedenen Parametereinstellungen ermittelt werden.\n",
    "\n",
    "Wir könnten nun zusätzliche Spalten mit den jeweiligen Präfixen und Suffixen in unseren Datentabellen ergänzen (evtl. auch zu Kleinschreibung normalisiert) und darauf einen `OneHotEncoder` anwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f2d383-75ea-474e-8cb5-69cf3b302443",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test.copy()\n",
    "tmp['suff4'] = tmp.word.str.lower().str[-4:]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a438b2-5812-4819-a88d-ca2ad5cb2436",
   "metadata": {},
   "source": [
    "Hier nützen wir stattdessen wieder den `CountVectorizer` mit einer geeigneten Tokenizer-Funktion (die alle gewünschten Suffixe und Präfixe zurückliefert) und der voreingestellten Normalisierung zu Kleinschreibung. Wichtig ist, dass Präfix und Suffix der gleichen Länge unterschieden werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01acbd71-c063-4cd2-9720-f1c12a415b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefix_suffix(word):\n",
    "    l = len(word)\n",
    "    res = []\n",
    "    for k in range(2, 5):\n",
    "        if l > k:\n",
    "            res.append(\"-\" + word[-k:])\n",
    "    for k in range(2, 4):\n",
    "        if l > k:\n",
    "            res.append(word[:k] + \"-\")\n",
    "    return(res)\n",
    "\n",
    "print(get_prefix_suffix(test.word[0]))\n",
    "print(get_prefix_suffix(test.word[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847e92b-d31a-497a-87ce-88f31f6c71a9",
   "metadata": {},
   "source": [
    "Sinnvoll sind vor allem Affixe, die häufig genug vorkommen, um zuverlässige Informationen zu liefern. Wir zeigen hier zunächst, welche Affixe bei $f\\ge 500$ verwendet werden. Für die tatsächliche Merkmalsextraktion verwenden wir dann einen weitaus niedrigeren Schwellenwert (der auch von der Länge $k$ des Affix abhängig gemacht werden könnte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db7941-dec8-4083-9695-7e4635d28b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=500)\n",
    "affix_vectorizer.fit(train.word)\n",
    "print(\" \".join(affix_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8a8e5-3565-4fa3-8dc9-172f289fc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=20)\n",
    "X_affix = affix_vectorizer.fit_transform(train.word)\n",
    "testX_affix = affix_vectorizer.transform(test.word)\n",
    "X_affix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d70b2-f8e2-4740-8277-bfce796e5a4d",
   "metadata": {},
   "source": [
    "Schließlich trainieren wir eine SVM mit der kombinierten Merkmalsmatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bd8e0-1070-441e-a882-83431ab45a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sp.sparse.hstack([X_wf, X_affix])\n",
    "testX = sp.sparse.hstack([testX_wf, testX_affix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569271c-4aa0-4e8d-8b4f-246149fd0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "%time clf.fit(X, train.pos)\n",
    "%time clf.score(testX, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826af57f-4d6d-4a54-8288-ef913ed50c89",
   "metadata": {},
   "source": [
    "### Weitere Merkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b795a0e-d7ae-4860-9b12-ff09f6c80438",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Extrahieren Sie spezifische Merkmale wie Groß-/Kleinschreibung, „Token besteht nur aus Ziffern“, „Token enthält keine Buchstaben“, „Bindestrich am Wortend“, Satzanfang, usw. als dicht besetzte Binärmatrix.  Denken Sie sich auch weitere Merkmale aus, die für die Wortartenerkennung nützlich sein könnten.  Fügen Sie die zusätzlichen Merkmale dann an die bisherige Merkmalsmatrix an.  Können Sie damit die Genauigkeit des Unigramm-Taggers verbessern?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61de52-908c-4b1c-b02c-0407ab8cae64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d09b027d-921f-4141-8afb-88fd387c348c",
   "metadata": {},
   "source": [
    "> **Frage:** Können Sie erklären, warum einige dieser Merkmale (z.B. die Markierung für den Satzanfang) von einem linearen Klassifikator (wie der hier verwendeten `LinearSVC`) nicht optimal genutzt werden? Wie könnte man angesichts dieser Erkenntnis die Ergebnisse möglicherweise noch etwas verbessern?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a04cb6-602e-495c-99c1-56feb368d9c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "680f84e1-096b-499d-8380-b112392f0c59",
   "metadata": {},
   "source": [
    "### Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe74f9e-7b5c-4ca9-9d06-3312271d9e33",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **Aufgabe:** Experimentieren Sie mit den Metaparametern des Lernverfahrens und der Merkmalsextraktion (z.B. OOV-Schwellenwert für Wortformen, maximale Länge der Präfixe und Suffixe, hinzufügen von weiteren spezifischen Merkmalen. Testen Sie auch andere Lernverfahren als SVM: können diese schneller trainiert werden? Denken Sie, dass eine systematische Optimierung der Metaparameter (insb. der Regularisierungsstärke) sinnvoll ist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a920905-f8b4-4699-8433-1201de639394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fcb899-dc7d-4eb8-8a7c-e4d4cab9f468",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
