{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e990edf-7023-4ad6-add0-110a176cf5ce",
   "metadata": {},
   "source": [
    "# POS-Tagging mit maschinellen Lernverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b35c312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa0a761-1436-485a-9b2b-eeb2060f4798",
   "metadata": {},
   "source": [
    "## Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af298cb1-95f6-413b-8c57-b333018bdc0c",
   "metadata": {},
   "source": [
    "Trainings (`_train`) und Testdaten (`_dev`) laden. Da die TSV-Tabellen keine Kopfzeile haben, müssen wir sinnvolle Spaltennamen selbst festlegen. Wichtig ist dabei, dass Anführungszeichen als normale Zeichen gelesen (`quoting=3`) und `null`, `N/A` usw. nicht als undefinierte Werte interpretiert werden (sehr unintuitiv mit `keep_default_na=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac6564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = (\"sent\", \"tok\", \"word\", \"pos\", \"lemma\", \"morph\")\n",
    "train = pd.read_csv(\"data/tiger2_train.tsv.gz\", sep=\"\\t\", names=header, quoting=3, keep_default_na=False)\n",
    "test = pd.read_csv(\"data/tiger2_dev.tsv.gz\",sep=\"\\t\",names=header, quoting=3, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5436bf-1581-4fc7-b000-24ced338dfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tok</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>morph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>$(</td>\n",
       "      <td>--</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Ross</td>\n",
       "      <td>NE</td>\n",
       "      <td>Ross</td>\n",
       "      <td>{\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"masc\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Perot</td>\n",
       "      <td>NE</td>\n",
       "      <td>Perot</td>\n",
       "      <td>{\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"masc\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>wäre</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>sein</td>\n",
       "      <td>{\"number\": \"sg\", \"person\": \"3\", \"tense\": \"past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>vielleicht</td>\n",
       "      <td>ADV</td>\n",
       "      <td>vielleicht</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449280</th>\n",
       "      <td>25000</td>\n",
       "      <td>10</td>\n",
       "      <td>``</td>\n",
       "      <td>$(</td>\n",
       "      <td>--</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449281</th>\n",
       "      <td>25000</td>\n",
       "      <td>11</td>\n",
       "      <td>wäre</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>sein</td>\n",
       "      <td>{\"number\": \"sg\", \"person\": \"3\", \"tense\": \"past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449282</th>\n",
       "      <td>25000</td>\n",
       "      <td>12</td>\n",
       "      <td>Zensur</td>\n",
       "      <td>NN</td>\n",
       "      <td>Zensur</td>\n",
       "      <td>{\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"fem\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449283</th>\n",
       "      <td>25000</td>\n",
       "      <td>13</td>\n",
       "      <td>''</td>\n",
       "      <td>$(</td>\n",
       "      <td>--</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449284</th>\n",
       "      <td>25000</td>\n",
       "      <td>14</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>--</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449285 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sent  tok        word    pos       lemma  \\\n",
       "0           1    1          ``     $(          --   \n",
       "1           1    2        Ross     NE        Ross   \n",
       "2           1    3       Perot     NE       Perot   \n",
       "3           1    4        wäre  VAFIN        sein   \n",
       "4           1    5  vielleicht    ADV  vielleicht   \n",
       "...       ...  ...         ...    ...         ...   \n",
       "449280  25000   10          ``     $(          --   \n",
       "449281  25000   11        wäre  VAFIN        sein   \n",
       "449282  25000   12      Zensur     NN      Zensur   \n",
       "449283  25000   13          ''     $(          --   \n",
       "449284  25000   14           .     $.          --   \n",
       "\n",
       "                                                    morph  \n",
       "0                                                      {}  \n",
       "1       {\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"masc\"}  \n",
       "2       {\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"masc\"}  \n",
       "3       {\"number\": \"sg\", \"person\": \"3\", \"tense\": \"past...  \n",
       "4                                                      {}  \n",
       "...                                                   ...  \n",
       "449280                                                 {}  \n",
       "449281  {\"number\": \"sg\", \"person\": \"3\", \"tense\": \"past...  \n",
       "449282   {\"case\": \"nom\", \"number\": \"sg\", \"gender\": \"fem\"}  \n",
       "449283                                                 {}  \n",
       "449284                                                 {}  \n",
       "\n",
       "[449285 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32342f4f-7ce6-4d46-81f1-26a205de0d0f",
   "metadata": {},
   "source": [
    "Wir benötigen nur die ersten 4 Spalten (`lemma` und `morph` können wir später für andere Aufgaben nutzen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27be37c5-24c1-40d4-8de8-d1420a85be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[:, 0:4]\n",
    "test = test.iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f454e68-0b78-4b52-aa8c-ae1b5ad36f3a",
   "metadata": {},
   "source": [
    "Strings werden in Pandas als Arrays vom Typ `object` eingelesen.  Wir können sie explizit in spezielle `StringArray`s konvertieren, die aber [momentan wohl noch keine besonderen Performance-Vorteile](https://pandas.pydata.org/docs/user_guide/text.html) bieten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e11dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sent     int64\n",
       "tok      int64\n",
       "word    string\n",
       "pos     string\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.word = train.word.astype('string')\n",
    "train.pos  = train.pos.astype('string')\n",
    "test.word  = test.word.astype('string')\n",
    "test.pos   = test.pos.astype('string')\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367edb-80ba-42fd-9b81-76916c759a82",
   "metadata": {},
   "source": [
    "## Unigramm-Tagger (ohne Kontext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45213690-49fc-45f7-af0e-4c4829043eba",
   "metadata": {},
   "source": [
    "Wir implementieren zunächst einen Unigramm-Tagger, der nur auf Wortformen arbeitet und keine Kontextinformation hinzuzieht. Das lässt sich besonders einfach mit der Pandas-Repräsentation der Trainingsdaten umsetzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e9a63-1504-4ae8-a2be-cff05ec40eb9",
   "metadata": {},
   "source": [
    "Das naheliegendste Merkmal sind die Wortformen selbst, für die wir ein Dummy Coding (_one-hot encoding_) erstellen müssen.  Dies lässt sich direkt mit dem `OneHotEncoder` erstellen (oder dem `DictVectorizer`, der aber wesentlich mehr Overhead produziert).  Ein besonders einfacher und flexibler Ansatz ist ein `CountVectorizer`, der jeweils nur ein Token als Eingabe bekommt und viele weitere Optionen anbietet.  Wir vergleichen hier die Verarbeitungsgeschwindigkeit aller drei Varianten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4a6e6-4abe-40e6-85a0-711bc1035fd5",
   "metadata": {},
   "source": [
    "**1) OneHotEncoder:** Erwartet Listen oder Tupeln von Merkmalswerten, die jeweils in ein _one-hot encoding_ überführt werden. Hier müssen wir die Wörter also in Tupel der Länge 1 transformieren. Die Option `handle_unknown` muss auf `'ignore'` gesetzt werden, damit unbekannte Wortformen in den Testdaten keinen Fehler werfen. Mit `min_frequency` und `'infrequent_if_exist'` kann eine OOV-Kodierung implementiert werden. Wir setzen hier eine Schwellenwert von $f \\ge 5$ an, damit nur halbwegs zuverlässige Lexikoninformation gelernt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957d2785-1a82-42c3-8efa-0093409d2dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 660 ms, sys: 34.1 ms, total: 694 ms\n",
      "Wall time: 698 ms\n",
      "CPU times: user 226 ms, sys: 10.2 ms, total: 236 ms\n",
      "Wall time: 236 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(449285, 8683)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_vectorizer = OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=5)\n",
    "%time X_wf = wf_vectorizer.fit_transform([(x,) for x in train.word])\n",
    "%time testX_wf = wf_vectorizer.transform([(x,) for x in test.word])\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff172ac-9edd-479b-8432-9f29356b11ec",
   "metadata": {},
   "source": [
    "**2) DictVectorizer:** Hier stehen keine Optionen zur Auswahl, insbesondere könnte ein Schwellenwert wie $f\\ge 5$ nur als zusätzliche Transformation der Merkmalsmatrix umgesetzt werden. Obwohl als Eingabe eine Liste von Dictionaries erstellt werden muss, ist dieser Ansatz schneller als der OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc75a28-5746-4661-b2c9-2e7a05571d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 446 ms, sys: 24.1 ms, total: 470 ms\n",
      "Wall time: 470 ms\n",
      "CPU times: user 189 ms, sys: 7.92 ms, total: 197 ms\n",
      "Wall time: 197 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(449285, 55803)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_vectorizer = DictVectorizer()\n",
    "%time X_wf = wf_vectorizer.fit_transform([{\"word\": x} for x in train.word])\n",
    "%time testX_wf = wf_vectorizer.transform([{\"word\": x} for x in test.word])\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4cd44d-102d-419c-a2e5-35b113d383e6",
   "metadata": {},
   "source": [
    "**3) CountVectorizer:** Wir können das _one-hot encoding_ auch mit einem `CountVectorizer` erzeugen, der jede Wortform als ein einzelnes Token behandelt (was durch einen geeigneten Custom-Tokenizer sichergestellt werden muss). Mit `binary=True` könnten wir auch explizit erzwingen, dass eine binäre Matrix erzeugt wird. Der Schwellenwert $f\\ge 5$ lässt sich leicht mit `min_df` anwenden (in der Binärmatrix ist ja $f = \\mathit{df}$); allerdings werden hier die OOV nicht explizit repräsentiert (sondern durch einen $\\mathbf{0}$-Vektor) und müssen implizit von dem maschinellen Lernverfahren gelernt werden. Dieser Ansatz ist zwar etwas langsamer als der `DictVectorizer`, wegen seiner Flexibilität aber vorzuziehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ef3e43-bf86-414c-8a25-e26e2d7f4cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 586 ms, sys: 8.13 ms, total: 595 ms\n",
      "Wall time: 595 ms\n",
      "CPU times: user 286 ms, sys: 1.92 ms, total: 288 ms\n",
      "Wall time: 288 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(449285, 8682)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_vectorizer = CountVectorizer(tokenizer=lambda x: (x,), lowercase=False, min_df=5)\n",
    "%time X_wf = wf_vectorizer.fit_transform(train.word)\n",
    "%time testX_wf = wf_vectorizer.transform(test.word)\n",
    "X_wf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30acd0c3-46b2-469a-87c0-cfd35c08d92a",
   "metadata": {},
   "source": [
    "Wir können nun ein erstes Lernexperiment mit einer linearen SVM durchführen (ohne Optimierung der Meta-Parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d25fc7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 s, sys: 99.5 ms, total: 44.1 s\n",
      "Wall time: 44.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_wf, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92641963-344f-4ec4-8f17-9e3cbf01ff30",
   "metadata": {},
   "source": [
    "Evaluation auf den Testdaten ergibt schon eine ganz passable Genauigkeit. Ein Vergleich mit den Trainingsdaten zeigt, dass die SVM kaum übertrainiert ist (**Frage:** Was könnte der Grund dafür sein?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a291ee99-7575-4324-8c7a-aea066e7d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8560863571662708\n",
      "0.8774074362598351\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(testX_wf)\n",
    "print(accuracy_score(predicted, test.pos))\n",
    "\n",
    "print(clf.score(X_wf, train.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305bfd9-8298-4a4f-8db1-9173acc18539",
   "metadata": {},
   "source": [
    "### Fehleranalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e882319-f1e8-441f-8ce4-b71e03318faa",
   "metadata": {},
   "source": [
    "Der beste Ausgangspunkt für eine gezielte Optimierung der Lernergebnisse ist oft eine detaillierte Fehleranalyse. Als ersten Schritte berechnen wir Precision und Recall separat für jede Kategorie, d.h. jedes POS-Tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4cca51f-6134-46a6-a27e-cf9cd6b7e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          $(       1.00      1.00      1.00      7574\n",
      "          $,       1.00      1.00      1.00     11330\n",
      "          $.       1.00      1.00      1.00     11335\n",
      "        ADJA       0.96      0.54      0.69     13517\n",
      "        ADJD       0.94      0.56      0.70      4743\n",
      "         ADV       0.93      0.91      0.92     10154\n",
      "        APPO       1.00      0.67      0.80        48\n",
      "        APPR       0.91      0.96      0.94     18869\n",
      "     APPRART       0.99      0.99      0.99      3686\n",
      "        APZR       0.75      0.22      0.34        81\n",
      "         ART       0.91      1.00      0.96     24212\n",
      "        CARD       1.00      0.78      0.88      3947\n",
      "          FM       0.56      0.02      0.03       313\n",
      "         ITJ       0.00      0.00      0.00         5\n",
      "       KOKOM       0.58      0.50      0.53       719\n",
      "         KON       0.99      0.95      0.97      5657\n",
      "        KOUI       0.81      0.12      0.20       258\n",
      "        KOUS       0.98      0.86      0.92      1794\n",
      "          NE       0.97      0.48      0.65     12857\n",
      "          NN       0.67      0.99      0.80     45920\n",
      "        PDAT       0.89      0.98      0.93       704\n",
      "         PDS       0.86      0.23      0.37       815\n",
      "        PIAT       0.87      0.81      0.84      1619\n",
      "         PIS       0.84      0.54      0.66      1164\n",
      "        PPER       0.99      0.99      0.99      3435\n",
      "      PPOSAT       0.97      0.92      0.95      1711\n",
      "       PPOSS       0.00      0.00      0.00         2\n",
      "      PRELAT       0.51      0.64      0.57        73\n",
      "       PRELS       0.79      0.03      0.06      1646\n",
      "         PRF       1.00      0.98      0.99      1529\n",
      "       PROAV       0.97      0.97      0.97      1261\n",
      "        PTKA       1.00      0.06      0.11       104\n",
      "      PTKANT       0.56      0.68      0.61        22\n",
      "      PTKNEG       1.00      1.00      1.00      1282\n",
      "       PTKVZ       0.75      0.27      0.40      1287\n",
      "       PTKZU       0.61      0.99      0.76      1090\n",
      "        PWAT       0.71      0.91      0.80        46\n",
      "        PWAV       0.93      0.51      0.66       484\n",
      "         PWS       0.79      0.99      0.88       238\n",
      "       TRUNC       1.00      0.14      0.25       304\n",
      "       VAFIN       0.98      0.96      0.97      6044\n",
      "       VAIMP       0.00      0.00      0.00         1\n",
      "       VAINF       0.64      0.86      0.73       754\n",
      "        VAPP       1.00      1.00      1.00       312\n",
      "       VMFIN       0.94      0.99      0.97      2179\n",
      "       VMINF       0.00      0.00      0.00       137\n",
      "        VMPP       0.00      0.00      0.00         3\n",
      "       VVFIN       0.92      0.57      0.71      9110\n",
      "       VVIMP       1.00      0.35      0.52        31\n",
      "       VVINF       0.71      0.57      0.63      3319\n",
      "       VVIZU       1.00      0.20      0.34       396\n",
      "        VVPP       0.86      0.63      0.73      4380\n",
      "          XY       1.00      0.33      0.49       202\n",
      "\n",
      "    accuracy                           0.86    222703\n",
      "   macro avg       0.79      0.62      0.65    222703\n",
      "weighted avg       0.88      0.86      0.84    222703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.pos, predicted, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b113e084-cf68-4f5c-8367-1eb634a3c71d",
   "metadata": {},
   "source": [
    "Schlechte Ergebnisse bei offenen Wortklassen könnten zu einem erheblichen Teil auf unbekannte Wörter zurückzuführen sein, für die immer die gleiche Wortart geraten wird. Bei geschlossenen Wortklassen deuten sie darauf hin, dass Kontextinformation zur Disambiguierung notwendig wäre. So etwa bei `PTKVZ` (abgetrennte Verbpartikel, z.B. _Stephanie geht <u>aus</u>_), die oft auch Präpositionen sein können.\n",
    "\n",
    "Um diese Hypothese näher zu untersuchen, können wir z.B. eine separate Evaluation nur für unbekannte Wörter durchführen. Wir erkennen diese daran, dass ihre Merkmalsvektoren $\\mathbf{0}$ sind. Wir sehen nun, dass alle unbekannten Wörter als `NN` getaggt werden und dass es sich dabei überwiegend um offene Wortklassen handelt (Spalte _support_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4d4ce49-b247-41bc-9dfc-cd62f7bbc667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ADJA       0.00      0.00      0.00      6047\n",
      "        ADJD       0.00      0.00      0.00      1900\n",
      "         ADV       0.00      0.00      0.00       472\n",
      "        APPR       0.00      0.00      0.00        72\n",
      "     APPRART       0.00      0.00      0.00        18\n",
      "        APZR       0.00      0.00      0.00         5\n",
      "         ART       0.00      0.00      0.00         6\n",
      "        CARD       0.00      0.00      0.00       838\n",
      "          FM       0.00      0.00      0.00       259\n",
      "         ITJ       0.00      0.00      0.00         3\n",
      "         KON       0.00      0.00      0.00         6\n",
      "        KOUI       0.00      0.00      0.00         2\n",
      "        KOUS       0.00      0.00      0.00        12\n",
      "          NE       0.00      0.00      0.00      6448\n",
      "          NN       0.46      1.00      0.63     19357\n",
      "        PDAT       0.00      0.00      0.00        12\n",
      "         PDS       0.00      0.00      0.00         6\n",
      "        PIAT       0.00      0.00      0.00        37\n",
      "         PIS       0.00      0.00      0.00        43\n",
      "        PPER       0.00      0.00      0.00         6\n",
      "      PPOSAT       0.00      0.00      0.00        14\n",
      "       PPOSS       0.00      0.00      0.00         1\n",
      "       PRELS       0.00      0.00      0.00         3\n",
      "         PRF       0.00      0.00      0.00         4\n",
      "       PROAV       0.00      0.00      0.00        32\n",
      "      PTKANT       0.00      0.00      0.00         1\n",
      "       PTKVZ       0.00      0.00      0.00        38\n",
      "        PWAT       0.00      0.00      0.00         4\n",
      "        PWAV       0.00      0.00      0.00        31\n",
      "       TRUNC       0.00      0.00      0.00       258\n",
      "       VAFIN       0.00      0.00      0.00        18\n",
      "       VMFIN       0.00      0.00      0.00        14\n",
      "        VMPP       0.00      0.00      0.00         3\n",
      "       VVFIN       0.00      0.00      0.00      2757\n",
      "       VVIMP       0.00      0.00      0.00        16\n",
      "       VVINF       0.00      0.00      0.00      1106\n",
      "       VVIZU       0.00      0.00      0.00       315\n",
      "        VVPP       0.00      0.00      0.00      1463\n",
      "          XY       0.00      0.00      0.00       120\n",
      "\n",
      "    accuracy                           0.46     41747\n",
      "   macro avg       0.01      0.03      0.02     41747\n",
      "weighted avg       0.21      0.46      0.29     41747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx_oov = testX_wf.sum(axis=1) == 0\n",
    "idx_oov = np.asarray(idx_oov).squeeze() # Spaltenvektor (Typ: np.matrix) in Vektor konvertieren\n",
    "print(classification_report(test.pos[idx_oov], predicted[idx_oov], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a24912-b0ba-4b97-8704-17b8a68a5642",
   "metadata": {},
   "source": [
    "Schließlich können wir noch eine Fehlermatrix (_confusion matrix_) berechnen, die die häufigsten Fehler aufzeigt und schön visualisiert werden kann. Da sich die volle Fehlermatrix nur schwer darstellen lässt, konzentrieren wir uns auf ausgewählte Wortarten, z.B. Substantive, Vollverben, Adjektive und Adverbien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b83ab3eb-1d3f-4e50-aa11-4c360e471380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "focus_tags = ('ADJA', 'ADJD', 'ADV', 'NE', 'NN', 'VVFIN', 'VVINF', 'VVIMP')\n",
    "cm = confusion_matrix(test.pos, predicted, labels=focus_tags)\n",
    "ConfusionMatrixDisplay(cm, display_labels=focus_tags).plot(cmap='OrRd');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51523a-018a-4526-a9fb-d87f33c87cca",
   "metadata": {},
   "source": [
    "Auffallend ist eine Spalte, mit zahlreichen Fehlern, bei denen das Lernverfahren `NN` vorhergesagt hat. Hier handelt es sich mutmaßlich zu einem großen Teil um unbekannte Wörter. Im nächsten Schritt gilt es nun also, Wortarten für solche unbekannten Wörter zu erraten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01876d2-80e8-4d94-a23d-701dbdcd42b1",
   "metadata": {},
   "source": [
    "### Präfix- und Suffixmerkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a688a-a0be-410d-9989-b6fecdfcab31",
   "metadata": {},
   "source": [
    "Die Wortart eines unbekannten Wortes lässt sich am ehesten aus der Endung (Suffix der letzten $k$ Zeichen, z.B. _-bares_) erraten, sowie teilweise auch aus dem Wortanfang (z.B. _ge-_). Wie viele Zeichen $k$ zu berücksichtigen sind, kann nur empirisch durch Experimente mit verschiedenen Parametereinstellungen ermittelt werden.\n",
    "\n",
    "Wir könnten nun zusätzliche Spalten mit den jeweiligen Präfixen und Suffixen in unseren Datentabellen ergänzen (evtl. auch zu Kleinschreibung normalisiert) und darauf einen `OneHotEncoder` anwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18f2d383-75ea-474e-8cb5-69cf3b302443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tok</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>suff4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>1</td>\n",
       "      <td>Der</td>\n",
       "      <td>ART</td>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001</td>\n",
       "      <td>2</td>\n",
       "      <td>Vertreter</td>\n",
       "      <td>NN</td>\n",
       "      <td>eter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25001</td>\n",
       "      <td>3</td>\n",
       "      <td>der</td>\n",
       "      <td>ART</td>\n",
       "      <td>der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25001</td>\n",
       "      <td>4</td>\n",
       "      <td>Brandt-Witwe</td>\n",
       "      <td>NN</td>\n",
       "      <td>itwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25001</td>\n",
       "      <td>5</td>\n",
       "      <td>sah</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>sah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222698</th>\n",
       "      <td>37498</td>\n",
       "      <td>2</td>\n",
       "      <td>steigen</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>igen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222699</th>\n",
       "      <td>37498</td>\n",
       "      <td>3</td>\n",
       "      <td>/</td>\n",
       "      <td>$(</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222700</th>\n",
       "      <td>37499</td>\n",
       "      <td>1</td>\n",
       "      <td>Weniger</td>\n",
       "      <td>PIAT</td>\n",
       "      <td>iger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222701</th>\n",
       "      <td>37499</td>\n",
       "      <td>2</td>\n",
       "      <td>Stellen</td>\n",
       "      <td>NN</td>\n",
       "      <td>llen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222702</th>\n",
       "      <td>37500</td>\n",
       "      <td>1</td>\n",
       "      <td>rb</td>\n",
       "      <td>XY</td>\n",
       "      <td>rb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222703 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sent  tok          word    pos suff4\n",
       "0       25001    1           Der    ART   der\n",
       "1       25001    2     Vertreter     NN  eter\n",
       "2       25001    3           der    ART   der\n",
       "3       25001    4  Brandt-Witwe     NN  itwe\n",
       "4       25001    5           sah  VVFIN   sah\n",
       "...       ...  ...           ...    ...   ...\n",
       "222698  37498    2       steigen  VVFIN  igen\n",
       "222699  37498    3             /     $(     /\n",
       "222700  37499    1       Weniger   PIAT  iger\n",
       "222701  37499    2       Stellen     NN  llen\n",
       "222702  37500    1            rb     XY    rb\n",
       "\n",
       "[222703 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = test.copy()\n",
    "tmp['suff4'] = tmp.word.str.lower().str[-4:]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a438b2-5812-4819-a88d-ca2ad5cb2436",
   "metadata": {},
   "source": [
    "Hier nützen wir stattdessen wieder den `CountVectorizer` mit einer geeigneten Tokenizer-Funktion (die alle gewünschten Suffixe und Präfixe zurückliefert) und der voreingestellten Normalisierung zu Kleinschreibung. Wichtig ist, dass Präfix und Suffix der gleichen Länge unterschieden werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01acbd71-c063-4cd2-9720-f1c12a415b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-er', 'De-']\n",
      "['-er', '-ter', '-eter', 'Ve-', 'Ver-']\n"
     ]
    }
   ],
   "source": [
    "def get_prefix_suffix(word):\n",
    "    l = len(word)\n",
    "    res = []\n",
    "    for k in range(2, 5):\n",
    "        if l > k:\n",
    "            res.append(\"-\" + word[-k:])\n",
    "    for k in range(2, 4):\n",
    "        if l > k:\n",
    "            res.append(word[:k] + \"-\")\n",
    "    return(res)\n",
    "\n",
    "print(get_prefix_suffix(test.word[0]))\n",
    "print(get_prefix_suffix(test.word[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847e92b-d31a-497a-87ce-88f31f6c71a9",
   "metadata": {},
   "source": [
    "Sinnvoll sind vor allem Affixe, die häufig genug vorkommen, um zuverlässige Informationen zu liefern. Wir zeigen hier zunächst, welche Affixe bei $f\\ge 500$ verwendet werden. Für die tatsächliche Merkmalsextraktion verwenden wir dann einen weitaus niedrigeren Schwellenwert (der auch von der Länge $k$ des Affix abhängig gemacht werden könnte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50db7941-dec8-4083-9695-7e4635d28b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Teaching/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-00 -abe -aben -ach -acht -aft -ag -age -agen -agte -ahr -al -alen -an -and -ang -ann -ar -ark -as -at -aten -atte -au -aus -aß -be -ben -ber -bt -ch -che -chen -cher -cht -chte -ck -de -den -der -dern -dt -dung -eben -eder -ef -egen -ehen -ehr -eht -ei -eich -eien -eil -ein -eine -eit -el -elt -em -en -end -ende -ene -enen -enn -ens -ent -er -ere -eren -ern -ers -ert -erte -es -ese -et -ete -eten -etzt -fe -fen -ft -ge -gen -ger -gt -gte -gung -haft -he -heit -hen -her -hl -hmen -hr -hre -hren -hrer -ht -hte -hten -ich -iche -icht -ie -ien -ier -iert -iese -ig -ige -igen -iger -igt -ik -il -in -ind -ine -inem -inen -iner -ines -ion -ir -ird -is -isch -ise -it -iten -itik -keit -ken -kt -land -ld -le -len -ler -lich -ll -lle -llen -ls -lt -lte -lten -lung -mber -me -men -mer -mmen -mt -nd -nde -nden -nder -ne -nem -nen -ner -nes -ng -ngen -nn -nnen -ns -nt -nte -nten -nter -nung -nz -och -oll -om -on -onen -or -rch -rd -rde -rden -re -ren -rer -rk -rn -rs -rt -rte -rten -rung -sch -sche -se -sen -ser -sse -ssen -st -ste -sten -ster -tag -te -ten -ter -tet -tig -tik -tion -ts -tt -tte -tten -tung -tz -tzt -uch -uen -uf -um -un -und -ung -ur -urch -urde -us -ut -ute -uß -ze -zen -zent -zt -ßen -ßt -ür 19- 199- ab- abe- abg- al- all- an- and- ang- ar- arb- au- auc- auf- aus- ba- be- beg- bei- ber- bes- bet- bi- bl- bo- br- bu- bun- ch- da- dam- dar- de- den- deu- di- die- do- dr- du- dur- ei- ein- en- ent- er- ers- et- eu- eur- fa- fe- fi- fl- fo- for- fr- fra- fre- fü- ga- ge- geb- gef- geg- geh- gel- gem- gen- ger- ges- gew- gi- gl- gr- gro- ha- hab- hat- hau- he- her- hi- hin- ho- hä- ih- ihr- im- in- int- is- ja- jah- je- jed- ju- ka- kan- ke- kei- ki- kl- ko- kom- kon- kr- kri- ku- kö- kön- la- lan- le- li- lä- ma- mac- man- mar- me- meh- men- mi- mil- min- mit- mo- mon- mu- mü- na- nac- nat- ne- neu- ni- nic- no- noc- nov- nu- od- ode- pa- par- pe- po- pol- pr- pro- prä- ra- re- rec- reg- ri- ro- ru- sa- sag- sc- sch- se- sei- sel- si- sic- sin- so- sol- son- soz- sp- st- sta- ste- str- ta- te- tei- to- tr- um- un- unt- us- ve- ver- vi- vie- vo- vor- wa- wah- war- we- wei- wel- wen- wer- wi- wie- wil- wir- wo- wol- wor- wu- wur- wä- ze- zei- zu- zus- zw- zwe- üb- übe-\n"
     ]
    }
   ],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=500)\n",
    "affix_vectorizer.fit(train.word)\n",
    "print(\" \".join(affix_vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dc8a8e5-3565-4fa3-8dc9-172f289fc16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449285, 3807)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affix_vectorizer = CountVectorizer(tokenizer=get_prefix_suffix, min_df=20)\n",
    "X_affix = affix_vectorizer.fit_transform(train.word)\n",
    "testX_affix = affix_vectorizer.transform(test.word)\n",
    "X_affix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358d70b2-f8e2-4740-8277-bfce796e5a4d",
   "metadata": {},
   "source": [
    "Schließlich trainieren wir eine SVM mit der kombinierten Merkmalsmatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b11bd8e0-1070-441e-a882-83431ab45a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sp.sparse.hstack([X_wf, X_affix])\n",
    "testX = sp.sparse.hstack([testX_wf, testX_affix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4569271c-4aa0-4e8d-8b4f-246149fd0b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 s, sys: 98.9 ms, total: 57.1 s\n",
      "Wall time: 57.2 s\n",
      "CPU times: user 178 ms, sys: 14.7 ms, total: 192 ms\n",
      "Wall time: 192 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.908663107367211"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "%time clf.fit(X, train.pos)\n",
    "%time clf.score(testX, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826af57f-4d6d-4a54-8288-ef913ed50c89",
   "metadata": {},
   "source": [
    "### Weitere Merkmale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df94dc-79ab-4bdf-a8d7-fb3dea817bff",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Extrahieren Sie spezifische Merkmale wie Groß-/Kleinschreibung, „Token besteht nur aus Ziffern“, „Token enthält keine Buchstaben“, „Bindestrich am Wortende“, Satzanfang, usw. als dicht besetzte Binärmatrix.  Denken Sie sich auch weitere Merkmale aus, die für die Wortartenerkennung nützlich sein könnten.  Fügen Sie die zusätzlichen Merkmale dann an die bisherige Merkmalsmatrix an.  Können Sie damit die Genauigkeit des Unigramm-Taggers verbessern?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587bcd89-182a-401e-aa66-c3cd1495a638",
   "metadata": {},
   "source": [
    "Solche spezifischen Merkmale können am besten mit einer eigenen Python-Funktion extrahiert werden. Dabei handelt es sich überwiegend um binäre Merkmale, z.B.: Groß-/Kleinschreibung, nur Ziffern, enthält keine Buchstaben (oder Ziffern), nur Großbuchstaben (oft eine Abkürzung), Token am Satzanfang (bzw. Satzende), Bindestrich am Wortende (Hinweis auf `TRUNC`). Mit solchem _feature engineering_ kann gezielt Information in das Lernverfahren eingebracht werden, die nach unserem linguistischen Verständnis relevant sein dürfte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49508100-9fc2-4fc0-9a6c-ee0174d1737b",
   "metadata": {},
   "source": [
    "Wir extrahieren alle Merkmale als (dicht besetzte) $\\{0, 1\\}$-Matrix. Alternativ könnten wir auch jeweils eine Liste aller vorliegenden Merkmale erstellen und mit einem CountVectorizer übersetzen.  Unsere Lösung hat den Vorteil, dass sie nicht erst „trainiert“ werden muss, da die Merkmale schon im Voraus feststehen.  Wir beschränken uns hier auf Merkmale, die sich leicht identifizieren lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2016d0e-f818-41f8-8d2b-8e381ecd09d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>upper</th>\n",
       "      <th>allcaps</th>\n",
       "      <th>digits</th>\n",
       "      <th>noalpha</th>\n",
       "      <th>noalnum</th>\n",
       "      <th>atstart</th>\n",
       "      <th>trunc</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>Fahning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>möchte</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>zusätzlich</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>den</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>Platz</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>über</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6361</th>\n",
       "      <td>Verkehrsflächen</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>für</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6363</th>\n",
       "      <td>Behausungen</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6364</th>\n",
       "      <td>nutzen</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6365</th>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6366</th>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6367</th>\n",
       "      <td>etwa</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368</th>\n",
       "      <td>9000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6369</th>\n",
       "      <td>nahe</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6370</th>\n",
       "      <td>an</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6371</th>\n",
       "      <td>Bahn-</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>und</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>Busstationen</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6374</th>\n",
       "      <td>gelegene</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>Kleingärten</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  upper  allcaps  digits  noalpha  noalnum  atstart  \\\n",
       "6355          Fahning   True    False   False    False    False     True   \n",
       "6356           möchte  False    False   False    False    False    False   \n",
       "6357       zusätzlich  False    False   False    False    False    False   \n",
       "6358              den  False    False   False    False    False    False   \n",
       "6359            Platz   True    False   False    False    False    False   \n",
       "6360             über  False    False   False    False    False    False   \n",
       "6361  Verkehrsflächen   True    False   False    False    False    False   \n",
       "6362              für  False    False   False    False    False    False   \n",
       "6363      Behausungen   True    False   False    False    False    False   \n",
       "6364           nutzen  False    False   False    False    False    False   \n",
       "6365                -  False    False   False     True     True    False   \n",
       "6366              und  False    False   False    False    False    False   \n",
       "6367             etwa  False    False   False    False    False    False   \n",
       "6368             9000  False    False    True     True    False    False   \n",
       "6369             nahe  False    False   False    False    False    False   \n",
       "6370               an  False    False   False    False    False    False   \n",
       "6371            Bahn-   True    False   False    False    False    False   \n",
       "6372              und  False    False   False    False    False    False   \n",
       "6373     Busstationen   True    False   False    False    False    False   \n",
       "6374         gelegene  False    False   False    False    False    False   \n",
       "6375      Kleingärten   True    False   False    False    False    False   \n",
       "6376                .  False    False   False     True     True    False   \n",
       "\n",
       "      trunc   long  \n",
       "6355  False  False  \n",
       "6356  False  False  \n",
       "6357  False  False  \n",
       "6358  False  False  \n",
       "6359  False  False  \n",
       "6360  False  False  \n",
       "6361  False   True  \n",
       "6362  False  False  \n",
       "6363  False  False  \n",
       "6364  False  False  \n",
       "6365   True  False  \n",
       "6366  False  False  \n",
       "6367  False  False  \n",
       "6368  False  False  \n",
       "6369  False  False  \n",
       "6370  False  False  \n",
       "6371   True  False  \n",
       "6372  False  False  \n",
       "6373  False  False  \n",
       "6374  False  False  \n",
       "6375  False  False  \n",
       "6376  False  False  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_other_features(df, test=False):\n",
    "    res = pd.DataFrame({\n",
    "        'word': df.word,\n",
    "        'upper': df.word.str.match(r'[A-ZÄÖÜ]'),\n",
    "        'allcaps': df.word.str.fullmatch(r'[A-ZÄÖÜ]+'),\n",
    "        'digits': df.word.str.fullmatch(r'-?[0-9][0-9.,]*'),\n",
    "        'noalpha': ~df.word.str.contains(r'[a-zäöü]', flags=re.IGNORECASE),\n",
    "        'noalnum': ~df.word.str.contains(r'[0-9a-zäöü]', flags=re.IGNORECASE),\n",
    "        'atstart': df.tok == 1,\n",
    "        'trunc': df.word.str.endswith('-'),\n",
    "        'long': df.word.str.len() >= 15,\n",
    "    })\n",
    "    if test:\n",
    "        return res\n",
    "    else:\n",
    "        return res.iloc[:, 1:].to_numpy(dtype=np.float64)\n",
    "\n",
    "get_other_features(train[6355:6377], test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe6216-c381-4b17-b2ac-9e6f0602a4ac",
   "metadata": {},
   "source": [
    "Nun können wir unsere Trainings- und Testdaten ergänzen …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f50e56f0-3560-4c52-8b74-2f148affa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other = get_other_features(train)\n",
    "X = sp.sparse.hstack([X_wf, X_affix, X_other])\n",
    "\n",
    "testX_other = get_other_features(test)\n",
    "testX = sp.sparse.hstack([testX_wf, testX_affix, testX_other])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad2ab5-0749-4053-b7c3-cb8716934cf4",
   "metadata": {},
   "source": [
    "… und unsere SVM erneut trainiern und evaluieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd44e3f7-cafb-416c-876e-510d5f4008f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 s, sys: 95.9 ms, total: 45.5 s\n",
      "Wall time: 45.5 s\n",
      "CPU times: user 176 ms, sys: 17.1 ms, total: 193 ms\n",
      "Wall time: 193 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.926022550212615"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "%time clf.fit(X, train.pos)\n",
    "%time clf.score(testX, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7ed41-a842-4a59-b50c-bd6106d1586d",
   "metadata": {},
   "source": [
    "Durch die zusätzlichen Merkmale gewinnen wir tatsächlich einige Prozentpunkte Genauigkeit – und das mit recht wenig Arbeitsaufwand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0935fb3-bb39-48fc-8c76-339fd2fb21d0",
   "metadata": {},
   "source": [
    "> **Frage:** Können Sie erklären, warum einige dieser Merkmale (z.B. die Markierung für den Satzanfang) von einem linearen Klassifikator (wie der hier verwendeten `LinearSVC`) nicht optimal genutzt werden? Wie könnte man angesichts dieser Erkenntnis die Ergebnisse möglicherweise noch etwas verbessern?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8bf74-aab0-4cc4-804c-ec8261720e6d",
   "metadata": {},
   "source": [
    "Information über den Satzanfang ist v.a. in Kombination mit anderen Merkmalen aussagekräftig, da insbesondere dort ein sonst kleingeschriebenes Wort (z.B. _ein_) mit großem Anfangsbuchstaben stehen kann (_Ein gutes Buch ist …_). Ein linearer Klassifikator kann solche Merkmalaskombinationen nicht ausnutzen, da jedes Merkmal lediglich ein individuelles Gewicht erhält. Ein polynomiale SVM (mit `degree=2`) könnte zwar Paare von Merkmalen berücksichtigen, ist aber für unseren großen und hochdimensionalen Trainingsdatensatz nicht effizient genug.\n",
    "\n",
    "Sinnvoll könnte es hier sein, am Satzanfang zusätzlich zur großgeschriebenen Wortform auch die kleingeschriebene Version zu den Merkmalen hinzuzufügen (in diesem Fall würde also ein _two-hot encoding_ entstehen).  Dieser Ansatz könnte noch verfeinert werden, z.B. wird die kleingeschrieben Version nur berücksichtigt wenn sie bereits im Vokabular enthalten ist (z.B. mit $f \\geq 5$) und/oder wenn die großgeschrieben Originalform ein OOV ist (damit hätten wir wieder ein _one-hot encoding_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211a301-54fc-451f-9593-3a8888232531",
   "metadata": {},
   "source": [
    "### Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebc1f1-96f8-4982-b702-752c13b6a4e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **Aufgabe:** Experimentieren Sie mit den Metaparametern des Lernverfahrens und der Merkmalsextraktion (z.B. OOV-Schwellenwert für Wortformen, maximale Länge der Präfixe und Suffixe, hinzufügen von weiteren spezifischen Merkmalen. Testen Sie auch andere Lernverfahren als SVM: können diese schneller trainiert werden? Denken Sie, dass eine systematische Optimierung der Metaparameter (insb. der Regularisierungsstärke) sinnvoll ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2af0a4-c185-45c7-8c8d-a5f25bb0da58",
   "metadata": {},
   "source": [
    "Vor einer Metaparameteroptimierung per Grid Search kann es hilfreich sein, durch Evaluation auf den Trainingsdaten zu überprüfen, ob die SVM bereits stark übertrainiert ist (d.h. zu hohe _variance_ aufweist) oder noch zu wenig lernen kann (d.h. sich durch starken _bias_ nicht gut an die Trainingsdaten anpassen kann). Hier liegt letztere Fall vor: auch auf den Trainingsdaten ist die Genauigkeit noch sehr schlecht und wir müssen weitere Merkmale hinzufügen, um eine deutliche Verbesserung zu erreichen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b13c853-18fa-4bfd-8938-8d4a2aa99ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402406045160644"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, train.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a421b-415b-4ffa-a201-07b2f43a4393",
   "metadata": {},
   "source": [
    "Für Experimente mit Parametern der Merkmalsextraktion (z.B. OOV-Schwellenwert, Länge der Präfixe und Suffixe, etc.) wäre es sehr vorteilhaft, die komplette Erstellung der Merkmalsmatrix in eine Funktion zu kapseln, die dann mit verschiedenen Parametern aufgerufen werden kann. Ansonsten muss bei jedem Durchgang die kombinierte Merkmalsmatrix sowohl für die Trainings- als auch die Testdaten neu zusammengefügt werden.\n",
    "\n",
    "Wir testen hier exemplarisch ein bag-of-words-Modell mit Schwellenwert $f\\geq 2$, sowohl einzeln als auch in Kombination mit den anderen Merkmalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7d7edee-5a27-4838-9d2e-b385355d66cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449285, 22859)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf2_vectorizer = OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=2)\n",
    "X_wf2 = wf2_vectorizer.fit_transform([(x,) for x in train.word])\n",
    "testX_wf2 = wf2_vectorizer.transform([(x,) for x in test.word])\n",
    "X_wf2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3596fbbe-c68b-4655-832d-d59d577c8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8849229691562305"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_wf2, train.pos)\n",
    "clf.score(testX_wf2, test.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ed7a9de-b0e6-40cf-a4ea-58e855d243a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931401911963467"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = sp.sparse.hstack([X_wf2, X_affix, X_other])\n",
    "testX2 = sp.sparse.hstack([testX_wf2, testX_affix, testX_other])\n",
    "clf = LinearSVC()\n",
    "clf.fit(X2, train.pos)\n",
    "clf.score(testX2, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6de3d-b700-4fd3-929d-541eed41b4f5",
   "metadata": {},
   "source": [
    "Tatsächlich können wir mit dem niedrigeren OOV-Schwellenwert eine kleine Verbesserung erzielen, auch in Kombination mit allen anderen Merkmalen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b955c-92a7-45ea-bdd4-af798bc8d9c6",
   "metadata": {},
   "source": [
    "Schließlich testen wir als alternatives Lernverfahren noch Stochastic Gradient Descent, das im Gegensatz zur SVM sehr leicht zu implementieren ist. Mit einer geeigneten Regularisierungsstärke (die hier tatsächlich ein „kritischer“ Parameter ist) erreichen wir fast genauso gute Ergebnisse wie mit der SVM, das Training dauert aber nur wenige Sekunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2964ef-729b-4573-8c24-33c054ec0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.5 s, sys: 171 ms, total: 16.6 s\n",
      "Wall time: 2.38 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9236651504470079"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf = SGDClassifier(alpha=1e-5, max_iter=5000, n_jobs=-1)\n",
    "clf.fit(X, train.pos)\n",
    "clf.score(testX, test.pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a97d77-b798-453e-afb9-2f5d4461273c",
   "metadata": {},
   "source": [
    "## Oberflächenkontext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c15c8-4ce6-4e70-9212-db9c01704dc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Zur kontextabhängigen Disambiguierung wollen wir nun auch die vorhergehenden und folgenden Token an jeder Stelle berücksichtigen. Dazu müssen wir satzweise vorgehen und entsprechendes _padding_ am Satzanfang und -ende hinzufügen (**Frage:** warum ist das unbedingt nötig?).\n",
    "\n",
    "Als Beispiel bearbeiten wir zunächst einen einzelnen Satz und definieren dann eine Funktion, die wir mit den Pandas-Methoden `groupy()` und `apply()` auf alle Sätze im Korpus anwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a29d38d5-f8ce-420a-9cb3-4dc3492ec9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tok</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>$(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>Die</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>Probleme</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>unseres</td>\n",
       "      <td>PPOSAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>Landes</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>sind</td>\n",
       "      <td>VAFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>doch</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>weit</td>\n",
       "      <td>ADJD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>größer</td>\n",
       "      <td>ADJD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>als</td>\n",
       "      <td>KOKOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>die</td>\n",
       "      <td>PDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>eines</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>Unternehmens</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>''</td>\n",
       "      <td>$(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>meint</td>\n",
       "      <td>VVFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Oswald</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>Chefvolkswirt</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>beim</td>\n",
       "      <td>APPRART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>Gewerkschaftsbund</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>AFL-CIO</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent  tok               word      pos\n",
       "790    42    1                 ``       $(\n",
       "791    42    2                Die      ART\n",
       "792    42    3           Probleme       NN\n",
       "793    42    4            unseres   PPOSAT\n",
       "794    42    5             Landes       NN\n",
       "795    42    6               sind    VAFIN\n",
       "796    42    7               doch      ADV\n",
       "797    42    8               weit     ADJD\n",
       "798    42    9             größer     ADJD\n",
       "799    42   10                als    KOKOM\n",
       "800    42   11                die      PDS\n",
       "801    42   12              eines      ART\n",
       "802    42   13       Unternehmens       NN\n",
       "803    42   14                 ''       $(\n",
       "804    42   15                  ,       $,\n",
       "805    42   16              meint    VVFIN\n",
       "806    42   17               Rudy       NE\n",
       "807    42   18             Oswald       NE\n",
       "808    42   19                  ,       $,\n",
       "809    42   20      Chefvolkswirt       NN\n",
       "810    42   21               beim  APPRART\n",
       "811    42   22  Gewerkschaftsbund       NN\n",
       "812    42   23            AFL-CIO       NE\n",
       "813    42   24                  .       $."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satz = train[train.sent == 42].copy()\n",
    "satz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810e197-cbd0-4167-9667-abf1e611ee22",
   "metadata": {},
   "source": [
    "Mit der Pandas-Methode `shift()` können wir die Spalten der Matrix um ein oder mehrere Token verschieben. Dabei müssen wir einen sinnvollen `fill_value` für das Padding angeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0af7e091-84db-41a9-9e4a-6eab2b53e74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tok</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>R1</th>\n",
       "      <th>posL1</th>\n",
       "      <th>posL2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>``</td>\n",
       "      <td>$(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Die</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>Die</td>\n",
       "      <td>ART</td>\n",
       "      <td>``</td>\n",
       "      <td></td>\n",
       "      <td>Probleme</td>\n",
       "      <td>$(</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>Probleme</td>\n",
       "      <td>NN</td>\n",
       "      <td>Die</td>\n",
       "      <td>``</td>\n",
       "      <td>unseres</td>\n",
       "      <td>ART</td>\n",
       "      <td>$(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>unseres</td>\n",
       "      <td>PPOSAT</td>\n",
       "      <td>Probleme</td>\n",
       "      <td>Die</td>\n",
       "      <td>Landes</td>\n",
       "      <td>NN</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>Landes</td>\n",
       "      <td>NN</td>\n",
       "      <td>unseres</td>\n",
       "      <td>Probleme</td>\n",
       "      <td>sind</td>\n",
       "      <td>PPOSAT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>sind</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>Landes</td>\n",
       "      <td>unseres</td>\n",
       "      <td>doch</td>\n",
       "      <td>NN</td>\n",
       "      <td>PPOSAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>doch</td>\n",
       "      <td>ADV</td>\n",
       "      <td>sind</td>\n",
       "      <td>Landes</td>\n",
       "      <td>weit</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>weit</td>\n",
       "      <td>ADJD</td>\n",
       "      <td>doch</td>\n",
       "      <td>sind</td>\n",
       "      <td>größer</td>\n",
       "      <td>ADV</td>\n",
       "      <td>VAFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>größer</td>\n",
       "      <td>ADJD</td>\n",
       "      <td>weit</td>\n",
       "      <td>doch</td>\n",
       "      <td>als</td>\n",
       "      <td>ADJD</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>als</td>\n",
       "      <td>KOKOM</td>\n",
       "      <td>größer</td>\n",
       "      <td>weit</td>\n",
       "      <td>die</td>\n",
       "      <td>ADJD</td>\n",
       "      <td>ADJD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>die</td>\n",
       "      <td>PDS</td>\n",
       "      <td>als</td>\n",
       "      <td>größer</td>\n",
       "      <td>eines</td>\n",
       "      <td>KOKOM</td>\n",
       "      <td>ADJD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>42</td>\n",
       "      <td>12</td>\n",
       "      <td>eines</td>\n",
       "      <td>ART</td>\n",
       "      <td>die</td>\n",
       "      <td>als</td>\n",
       "      <td>Unternehmens</td>\n",
       "      <td>PDS</td>\n",
       "      <td>KOKOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>Unternehmens</td>\n",
       "      <td>NN</td>\n",
       "      <td>eines</td>\n",
       "      <td>die</td>\n",
       "      <td>''</td>\n",
       "      <td>ART</td>\n",
       "      <td>PDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>''</td>\n",
       "      <td>$(</td>\n",
       "      <td>Unternehmens</td>\n",
       "      <td>eines</td>\n",
       "      <td>,</td>\n",
       "      <td>NN</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "      <td>''</td>\n",
       "      <td>Unternehmens</td>\n",
       "      <td>meint</td>\n",
       "      <td>$(</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>42</td>\n",
       "      <td>16</td>\n",
       "      <td>meint</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>,</td>\n",
       "      <td>''</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>$,</td>\n",
       "      <td>$(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>NE</td>\n",
       "      <td>meint</td>\n",
       "      <td>,</td>\n",
       "      <td>Oswald</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>$,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>Oswald</td>\n",
       "      <td>NE</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>meint</td>\n",
       "      <td>,</td>\n",
       "      <td>NE</td>\n",
       "      <td>VVFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "      <td>Oswald</td>\n",
       "      <td>Rudy</td>\n",
       "      <td>Chefvolkswirt</td>\n",
       "      <td>NE</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>Chefvolkswirt</td>\n",
       "      <td>NN</td>\n",
       "      <td>,</td>\n",
       "      <td>Oswald</td>\n",
       "      <td>beim</td>\n",
       "      <td>$,</td>\n",
       "      <td>NE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>42</td>\n",
       "      <td>21</td>\n",
       "      <td>beim</td>\n",
       "      <td>APPRART</td>\n",
       "      <td>Chefvolkswirt</td>\n",
       "      <td>,</td>\n",
       "      <td>Gewerkschaftsbund</td>\n",
       "      <td>NN</td>\n",
       "      <td>$,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>42</td>\n",
       "      <td>22</td>\n",
       "      <td>Gewerkschaftsbund</td>\n",
       "      <td>NN</td>\n",
       "      <td>beim</td>\n",
       "      <td>Chefvolkswirt</td>\n",
       "      <td>AFL-CIO</td>\n",
       "      <td>APPRART</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>AFL-CIO</td>\n",
       "      <td>NE</td>\n",
       "      <td>Gewerkschaftsbund</td>\n",
       "      <td>beim</td>\n",
       "      <td>.</td>\n",
       "      <td>NN</td>\n",
       "      <td>APPRART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>42</td>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>AFL-CIO</td>\n",
       "      <td>Gewerkschaftsbund</td>\n",
       "      <td></td>\n",
       "      <td>NE</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent  tok               word      pos                 L1  \\\n",
       "790    42    1                 ``       $(                      \n",
       "791    42    2                Die      ART                 ``   \n",
       "792    42    3           Probleme       NN                Die   \n",
       "793    42    4            unseres   PPOSAT           Probleme   \n",
       "794    42    5             Landes       NN            unseres   \n",
       "795    42    6               sind    VAFIN             Landes   \n",
       "796    42    7               doch      ADV               sind   \n",
       "797    42    8               weit     ADJD               doch   \n",
       "798    42    9             größer     ADJD               weit   \n",
       "799    42   10                als    KOKOM             größer   \n",
       "800    42   11                die      PDS                als   \n",
       "801    42   12              eines      ART                die   \n",
       "802    42   13       Unternehmens       NN              eines   \n",
       "803    42   14                 ''       $(       Unternehmens   \n",
       "804    42   15                  ,       $,                 ''   \n",
       "805    42   16              meint    VVFIN                  ,   \n",
       "806    42   17               Rudy       NE              meint   \n",
       "807    42   18             Oswald       NE               Rudy   \n",
       "808    42   19                  ,       $,             Oswald   \n",
       "809    42   20      Chefvolkswirt       NN                  ,   \n",
       "810    42   21               beim  APPRART      Chefvolkswirt   \n",
       "811    42   22  Gewerkschaftsbund       NN               beim   \n",
       "812    42   23            AFL-CIO       NE  Gewerkschaftsbund   \n",
       "813    42   24                  .       $.            AFL-CIO   \n",
       "\n",
       "                    L2                 R1    posL1    posL2  \n",
       "790                                   Die        *        *  \n",
       "791                              Probleme       $(        *  \n",
       "792                 ``            unseres      ART       $(  \n",
       "793                Die             Landes       NN      ART  \n",
       "794           Probleme               sind   PPOSAT       NN  \n",
       "795            unseres               doch       NN   PPOSAT  \n",
       "796             Landes               weit    VAFIN       NN  \n",
       "797               sind             größer      ADV    VAFIN  \n",
       "798               doch                als     ADJD      ADV  \n",
       "799               weit                die     ADJD     ADJD  \n",
       "800             größer              eines    KOKOM     ADJD  \n",
       "801                als       Unternehmens      PDS    KOKOM  \n",
       "802                die                 ''      ART      PDS  \n",
       "803              eines                  ,       NN      ART  \n",
       "804       Unternehmens              meint       $(       NN  \n",
       "805                 ''               Rudy       $,       $(  \n",
       "806                  ,             Oswald    VVFIN       $,  \n",
       "807              meint                  ,       NE    VVFIN  \n",
       "808               Rudy      Chefvolkswirt       NE       NE  \n",
       "809             Oswald               beim       $,       NE  \n",
       "810                  ,  Gewerkschaftsbund       NN       $,  \n",
       "811      Chefvolkswirt            AFL-CIO  APPRART       NN  \n",
       "812               beim                  .       NN  APPRART  \n",
       "813  Gewerkschaftsbund                          NE       NN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satz[\"L1\"] = satz.word.shift(1, fill_value=\"\")  # w_{t-1}\n",
    "satz[\"L2\"] = satz.word.shift(2, fill_value=\"\")  # w_{t-2}\n",
    "satz[\"R1\"] = satz.word.shift(-1, fill_value=\"\") # w_{t+1}\n",
    "satz[\"posL1\"] = satz.pos.shift(1, fill_value=\"*\") # für Trigramm-Tagger (später)\n",
    "satz[\"posL2\"] = satz.pos.shift(2, fill_value=\"*\")\n",
    "satz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7210550b-bc06-4bca-aad6-fb0a1eab5cfb",
   "metadata": {},
   "source": [
    "Nun erweitern wir die Trainings- und Testdaten um diese 5 Spalten. Hier zeigt sich Pandas als sehr elegante Lösung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b6d21e-fefd-4ab5-82c8-d469470124e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.4 s, sys: 202 ms, total: 15.6 s\n",
      "Wall time: 15.5 s\n",
      "CPU times: user 7.37 s, sys: 145 ms, total: 7.51 s\n",
      "Wall time: 7.43 s\n"
     ]
    }
   ],
   "source": [
    "def add_context(satz):\n",
    "    satz[\"L1\"] = satz.word.shift(1, fill_value=\"\")  # w_{t-1}\n",
    "    satz[\"L2\"] = satz.word.shift(2, fill_value=\"\")  # w_{t-2}\n",
    "    satz[\"R1\"] = satz.word.shift(-1, fill_value=\"\") # w_{t+1}\n",
    "    satz[\"posL1\"] = satz.pos.shift(1, fill_value=\"*\") # für Trigramm-Tagger (später)\n",
    "    satz[\"posL2\"] = satz.pos.shift(2, fill_value=\"*\")\n",
    "    return satz\n",
    "\n",
    "%time train = train.groupby('sent').apply(add_context)\n",
    "%time test = test.groupby('sent').apply(add_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15854af3-7847-4104-a535-161febcf6f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tok</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>R1</th>\n",
       "      <th>posL1</th>\n",
       "      <th>posL2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>1</td>\n",
       "      <td>Der</td>\n",
       "      <td>ART</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Vertreter</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25001</td>\n",
       "      <td>2</td>\n",
       "      <td>Vertreter</td>\n",
       "      <td>NN</td>\n",
       "      <td>Der</td>\n",
       "      <td></td>\n",
       "      <td>der</td>\n",
       "      <td>ART</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25001</td>\n",
       "      <td>3</td>\n",
       "      <td>der</td>\n",
       "      <td>ART</td>\n",
       "      <td>Vertreter</td>\n",
       "      <td>Der</td>\n",
       "      <td>Brandt-Witwe</td>\n",
       "      <td>NN</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25001</td>\n",
       "      <td>4</td>\n",
       "      <td>Brandt-Witwe</td>\n",
       "      <td>NN</td>\n",
       "      <td>der</td>\n",
       "      <td>Vertreter</td>\n",
       "      <td>sah</td>\n",
       "      <td>ART</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25001</td>\n",
       "      <td>5</td>\n",
       "      <td>sah</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>Brandt-Witwe</td>\n",
       "      <td>der</td>\n",
       "      <td>es</td>\n",
       "      <td>NN</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25001</td>\n",
       "      <td>6</td>\n",
       "      <td>es</td>\n",
       "      <td>PPER</td>\n",
       "      <td>sah</td>\n",
       "      <td>Brandt-Witwe</td>\n",
       "      <td>anders</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25001</td>\n",
       "      <td>7</td>\n",
       "      <td>anders</td>\n",
       "      <td>ADV</td>\n",
       "      <td>es</td>\n",
       "      <td>sah</td>\n",
       "      <td>.</td>\n",
       "      <td>PPER</td>\n",
       "      <td>VVFIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25001</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>anders</td>\n",
       "      <td>es</td>\n",
       "      <td></td>\n",
       "      <td>ADV</td>\n",
       "      <td>PPER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25002</td>\n",
       "      <td>1</td>\n",
       "      <td>Die</td>\n",
       "      <td>ART</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Gedächtnismünze</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25002</td>\n",
       "      <td>2</td>\n",
       "      <td>Gedächtnismünze</td>\n",
       "      <td>NN</td>\n",
       "      <td>Die</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>ART</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25002</td>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "      <td>Gedächtnismünze</td>\n",
       "      <td>Die</td>\n",
       "      <td>die</td>\n",
       "      <td>NN</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25002</td>\n",
       "      <td>4</td>\n",
       "      <td>die</td>\n",
       "      <td>PRELS</td>\n",
       "      <td>,</td>\n",
       "      <td>Gedächtnismünze</td>\n",
       "      <td>aufgrund</td>\n",
       "      <td>$,</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25002</td>\n",
       "      <td>5</td>\n",
       "      <td>aufgrund</td>\n",
       "      <td>APPR</td>\n",
       "      <td>die</td>\n",
       "      <td>,</td>\n",
       "      <td>ihres</td>\n",
       "      <td>PRELS</td>\n",
       "      <td>$,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25002</td>\n",
       "      <td>6</td>\n",
       "      <td>ihres</td>\n",
       "      <td>PPOSAT</td>\n",
       "      <td>aufgrund</td>\n",
       "      <td>die</td>\n",
       "      <td>Preises</td>\n",
       "      <td>APPR</td>\n",
       "      <td>PRELS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25002</td>\n",
       "      <td>7</td>\n",
       "      <td>Preises</td>\n",
       "      <td>NN</td>\n",
       "      <td>ihres</td>\n",
       "      <td>aufgrund</td>\n",
       "      <td>und</td>\n",
       "      <td>PPOSAT</td>\n",
       "      <td>APPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25002</td>\n",
       "      <td>8</td>\n",
       "      <td>und</td>\n",
       "      <td>KON</td>\n",
       "      <td>Preises</td>\n",
       "      <td>ihres</td>\n",
       "      <td>der</td>\n",
       "      <td>NN</td>\n",
       "      <td>PPOSAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25002</td>\n",
       "      <td>9</td>\n",
       "      <td>der</td>\n",
       "      <td>ART</td>\n",
       "      <td>und</td>\n",
       "      <td>Preises</td>\n",
       "      <td>eingeschränkten</td>\n",
       "      <td>KON</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25002</td>\n",
       "      <td>10</td>\n",
       "      <td>eingeschränkten</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>der</td>\n",
       "      <td>und</td>\n",
       "      <td>Auflage</td>\n",
       "      <td>ART</td>\n",
       "      <td>KON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25002</td>\n",
       "      <td>11</td>\n",
       "      <td>Auflage</td>\n",
       "      <td>NN</td>\n",
       "      <td>eingeschränkten</td>\n",
       "      <td>der</td>\n",
       "      <td>nur</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>25002</td>\n",
       "      <td>12</td>\n",
       "      <td>nur</td>\n",
       "      <td>ADV</td>\n",
       "      <td>Auflage</td>\n",
       "      <td>eingeschränkten</td>\n",
       "      <td>einem</td>\n",
       "      <td>NN</td>\n",
       "      <td>ADJA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sent  tok             word     pos               L1               L2  \\\n",
       "0   25001    1              Der     ART                                     \n",
       "1   25001    2        Vertreter      NN              Der                    \n",
       "2   25001    3              der     ART        Vertreter              Der   \n",
       "3   25001    4     Brandt-Witwe      NN              der        Vertreter   \n",
       "4   25001    5              sah   VVFIN     Brandt-Witwe              der   \n",
       "5   25001    6               es    PPER              sah     Brandt-Witwe   \n",
       "6   25001    7           anders     ADV               es              sah   \n",
       "7   25001    8                .      $.           anders               es   \n",
       "8   25002    1              Die     ART                                     \n",
       "9   25002    2  Gedächtnismünze      NN              Die                    \n",
       "10  25002    3                ,      $,  Gedächtnismünze              Die   \n",
       "11  25002    4              die   PRELS                ,  Gedächtnismünze   \n",
       "12  25002    5         aufgrund    APPR              die                ,   \n",
       "13  25002    6            ihres  PPOSAT         aufgrund              die   \n",
       "14  25002    7          Preises      NN            ihres         aufgrund   \n",
       "15  25002    8              und     KON          Preises            ihres   \n",
       "16  25002    9              der     ART              und          Preises   \n",
       "17  25002   10  eingeschränkten    ADJA              der              und   \n",
       "18  25002   11          Auflage      NN  eingeschränkten              der   \n",
       "19  25002   12              nur     ADV          Auflage  eingeschränkten   \n",
       "\n",
       "                 R1   posL1   posL2  \n",
       "0         Vertreter       *       *  \n",
       "1               der     ART       *  \n",
       "2      Brandt-Witwe      NN     ART  \n",
       "3               sah     ART      NN  \n",
       "4                es      NN     ART  \n",
       "5            anders   VVFIN      NN  \n",
       "6                 .    PPER   VVFIN  \n",
       "7                       ADV    PPER  \n",
       "8   Gedächtnismünze       *       *  \n",
       "9                 ,     ART       *  \n",
       "10              die      NN     ART  \n",
       "11         aufgrund      $,      NN  \n",
       "12            ihres   PRELS      $,  \n",
       "13          Preises    APPR   PRELS  \n",
       "14              und  PPOSAT    APPR  \n",
       "15              der      NN  PPOSAT  \n",
       "16  eingeschränkten     KON      NN  \n",
       "17          Auflage     ART     KON  \n",
       "18              nur    ADJA     ART  \n",
       "19            einem      NN    ADJA  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981dcc4-f6fc-4754-a28a-1987c52c1754",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Extrahieren Sie passende Merkmalsvektoren für die Kontextwörtern `L1`, `L2` und `R1` (analog dazu, wie wir es oben für das jeweils zu taggende Token gemacht haben).  Da es sich um das gleiche Wortformeninventar handelt wie bei der Spalte `word`, können Sie die bereits trainierten Vectorizer weiterverwenden.  (**Frage:** Warum könnte es dennoch sinnvoll sein, eigene Vectorizer für die Kontextwörter zu trainieren? Denken Sie insbesondere an Satzanfang und -ende.)\n",
    ">\n",
    "> Definieren Sie dazu die Funktion `get_features(tok, word)`, die zwei Vektoren mit den Token-Nummern und den Wortformen als Argumente erwartet und daraus eine vollständige Merkmalsmatrix (mit Wortform-, Affix- und den weiteren Merkmalen) erstellt. Der Aufruf `get_features(train.tok, train.word)` sollte genau die ursprüngliche Merkmalsmatrix `X` zurückliefern. Sie können dann z.B. mit `get_features(train.tok - 1, train.L1)` Kontextmerkmale für das vorangehende Wort ermitteln.\n",
    "> \n",
    "> Fügen Sie dann mit `sp.sparse.hstack()` alle Merkmalsvektoren zu einer großen Merkmalsmatrix `X2` zusammen. Erstellen Sie auch eine entsprechende Merkmalsmatrix `testX2` für die Testdaten. Bitte halten Sie sich an die vorgegebenen Variablennamen, damit der Programmcode weiter unten korrekt funktioniert. (**Tipp:** Es bietet sich an, geeignete Hilfsfunktionen zu definieren, um allzu viel Copy & Paste zu vermeiden.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92f7d0-f025-4637-bffd-44a586acd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(tok, word):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429162d4-1c2e-4475-9880-3b09d4e8ab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa88e3-04fe-485c-88f8-d99966be8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = None\n",
    "testX3 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd3062c-1392-4666-88ba-996c4ecd2c21",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Trainieren Sie jetzt ein geeignetes Klassifikationsverfahren auf der Merkmalsmatrix mit Oberflächenkontext und evaluieren Sie es auf den Testdaten. Wie beurteilen Sie die Ergebnisse? Experimentieren Sie dabei auch mit den Metaparametern des Lernverfahrens und probieren Sie ggf. unterschiedliche Anzahlen von Kontextwörtern aus. Führen Sie schließlich eine erneute Fehleranalyse durch.\n",
    ">\n",
    "> **Tipp:** Wir haben oben mit Stochastic Gradient Descent (bei einer Regularisierungsstärke von $\\alpha = 10^{-5}$) gute Erfahrungen gemacht. Mit diesem Lernverfahren werden Ihnen die folgenden Experimente wesentlich weniger Geduld abverlangen. (Denken Sie daran, `n_jobs=-1` anzugeben!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22464788-f47e-411d-bb19-5ff0c05d4faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033d06d-4aa3-4141-ad6f-9ebf09459922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f4110fc-b083-43fd-81b8-912276ebcf02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21fdc1f-3225-4a32-ae12-2562630d4b17",
   "metadata": {},
   "source": [
    "## Trigramm-Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38787b90-4c12-4105-8e60-4e878e4d905b",
   "metadata": {},
   "source": [
    "Zum Schluss skizzieren wir noch die Implementierung eines Trigramm-Taggers als maschinelles Lernverfahren. Im Grunde fügen wir die zwei vorangehenden Tags mit _dummy coding_ an die Merkmalsmatrix an. Da lineare Klassifikatoren keine Merkmalskombinationen lernen können, müssen wir das Bigramm `posL2 posL1` explizit als Merkmal ergänzen. Am bequemsten ist hier ein `OneHotEncoder`, der mit oder ohne OOV konfiguriert werden kann und der sich sogar direkt auf einen DataFrame anwenden lässt (hier aber etwas günstiger mit einer Numpy-Matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6be9e2b-600e-4e28-a906-a75e15d6ccd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449285, 1096)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_vectorizer = OneHotEncoder(handle_unknown = 'infrequent_if_exist', min_frequency=5)\n",
    "tmp = np.vstack([train.posL1, train.posL2, train.posL2 + \" \" + train.posL1]).T\n",
    "X_pos = pos_vectorizer.fit_transform(tmp)\n",
    "X_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5816ed52-a15a-4f7b-a5ba-2dcbdbaa74f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222703, 1096)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.vstack([test.posL1, test.posL2, test.posL2 + \" \" + test.posL1]).T\n",
    "testX_pos = pos_vectorizer.transform(tmp)\n",
    "testX_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b1ce1a-94e1-4e0c-9b19-4e8640880732",
   "metadata": {},
   "source": [
    "> **Aufgabe:** Fügen Sie die zusätzlichen Merkmale zur Merkmalsmatrix `X2` hinzu (und analog für die Testdaten). Halten Sie sich wiederum an die unten vorgegebenen Variablennamen. Trainieren Sie dann eine **lineare SVM** auf der erweiterten Merkmalsmatrix und evaluieren Sie sie auf den Testdaten.\n",
    "> \n",
    "> **Frage:** Sind diese Evaluationsergebnisse realistisch, d.h. können wir auf unbekannten Texten eine vergleichbare Genauigkeit erwarten wie auf den Testdaten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b1e5da7-d204-416c-945e-882cdae87e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = None\n",
    "testX3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014a262-cf92-4383-bd6d-3b8c6173f4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7e8622f-bc97-4c5b-8c88-49a501ccdb44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78b7838f-1d9e-4aee-9963-8491da6b0b43",
   "metadata": {},
   "source": [
    "### Greedy Tagger\n",
    "\n",
    "Um diesen Tagger überhaupt auf neue Eingabesätze anwenden zu können, für die im Gegensatz zu unseren Testdaten noch keine POS-Tags vorliegen, müssen wir jedes Token einzeln verarbeiten und für das nächste Token dann jeweils die POS-Kontextmerkmale an den Merkmalsvektor anhängen.  Wir definieren dazu eine Hilfsfunktion, die einen einzelnen Satz aus dem Testkorpus in dieser Form verarbeitet. Wir müssen dabei sicherstellen, dass die Matrix im CSR-Format vorliegt, um nachher leicht einzelne Merkmalsvektoren (= Zeilen) herausgreifen zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2028d4bf-bb2b-4ab4-b707-8ecd02ee9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features(satz):\n",
    "    return sp.sparse.hstack([\n",
    "        get_features(satz.tok, satz.word),\n",
    "        get_features(satz.tok - 1, satz.L1),\n",
    "        get_features(satz.tok - 2, satz.L2),\n",
    "        get_features(satz.tok + 1, satz.R1),\n",
    "    ], format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be3cbc-d11f-41b8-a16d-140376126292",
   "metadata": {},
   "source": [
    "Um einen Satz mit dem Greedy Tagger zu verarbeiten, erstellen wir zunächst eine Merkmalsmatrix analog zu `X2` für den Satz. Wir gehen diese Matrix dann Zeile für Zeile durch, hängen an den Merkmalsvektor die Merkmale für die vorhergehenden POS-Tags an (um einen Vektor analog zu `X3` zu erhalten) und wenden den Klassifikator auf den resultierenden Zeilenvektor an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "682dbf3a-dabd-4e52-af66-061479cd6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(satz):\n",
    "    n = satz.shape[0]\n",
    "    X = get_all_features(satz) # Matrix der Oberflächenmerkmale\n",
    "    tags = []\n",
    "    p1 = p2 = \"*\"              # vorhergehende POS-Tags\n",
    "    for i in range(n):\n",
    "        x1 = X[i, :]\n",
    "        x2 = pos_vectorizer.transform(np.array([[p1, p2, p2 + \" \" + p1]]))\n",
    "        x = sp.sparse.hstack([x1, x2])\n",
    "        tag = clf.predict(x)[0] # liefert NumPy-Array zurück\n",
    "        tags.append(tag)\n",
    "        p2, p1 = p1, tag\n",
    "    return pd.Series(tags, index=satz.index, dtype='string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6d57c-0827-411c-a2b6-1cc82a1bd867",
   "metadata": {},
   "outputs": [],
   "source": [
    "satz['tag'] = tag_sentence(satz)\n",
    "satz.loc[:, (\"sent\", \"tok\", \"word\", \"pos\", \"tag\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8db255-9d8e-45e3-9fe9-3cb1f09bf985",
   "metadata": {},
   "source": [
    "Diese Funktion müssen wir nun auf jeden Satz der Testdaten anwenden, was deutlich länger dauern wird als bisher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c1267-f155-4df3-b563-dbabea1b6a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predicted = test.groupby('sent').apply(tag_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc82a22-fc9b-4ae5-8aa8-3270cf445786",
   "metadata": {},
   "source": [
    "Die realistisch berechnete Genauigkeit ist kaum besser als beim Tagger, der nur Oberflächenkontext genutzt hat. Daher stellt sich die Frage, ob der viel höhere Zeitaufwand gerechtfertigt ist! Vielleicht lässt sich auch ohne Sequenzmodell durch weitere Optimierungen ein hinreichend guter Tagger implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedfc21-2498-41e2-b1ea-a6c7084787da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(predicted, test.pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f35052-6074-4d6f-b4ea-cdd5ce13a4ba",
   "metadata": {},
   "source": [
    "**Tipp:** Eine Evaluation auf den Trainingsdaten legt nahe, dass die SVM hochgradig übertrainiert ist. Möglicherweise würde eine stärkere Regularisierung oder eine geeignete Merkmalsselektion die Genauigkeit auf den Testdaten verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d1512-a555-4e91-9050-479217bcc9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.score(X3, train.pos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
