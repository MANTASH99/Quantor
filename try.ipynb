{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  b id  word_S  lexical_density   nn_W  np_W  nominal_W  \\\n",
      "0  icesing_s1a-001_1_1     8.0            0.250  0.000   0.0        0.0   \n",
      "1  icesing_s1a-001_1_2    16.0            0.625  0.125   0.0        0.0   \n",
      "2  icesing_s1a-001_1_3     1.0            0.000  0.000   0.0        0.0   \n",
      "3  icesing_s1a-001_1_5     5.0            0.400  0.200   0.0        0.0   \n",
      "4  icesing_s1a-001_1_6    10.0            0.500  0.100   0.0        0.0   \n",
      "\n",
      "   neoclass_W  poss_pronoun_W  pronoun_all_W  p1_perspron_P  ...  time_adv_W  \\\n",
      "0         0.0             0.0         0.1250       0.000000  ...         0.0   \n",
      "1         0.0             0.0         0.1875       0.333333  ...         0.0   \n",
      "2         0.0             0.0         0.0000       0.000000  ...         0.0   \n",
      "3         0.0             0.2         0.4000       0.500000  ...         0.0   \n",
      "4         0.0             0.0         0.0000       0.000000  ...         0.1   \n",
      "\n",
      "   nom_initial_S  prep_initial_S  adv_initial_S  text_initial_S  wh_initial_S  \\\n",
      "0            0.0               0            0.0               0           0.0   \n",
      "1            1.0               0            0.0               0           0.0   \n",
      "2            0.0               0            0.0               0           0.0   \n",
      "3            1.0               0            0.0               0           0.0   \n",
      "4            0.0               0            1.0               0           0.0   \n",
      "\n",
      "   disc_initial_S  nonfin_initial_S  subord_initial_S  verb_initial_S  \n",
      "0               0                 0                 0             1.0  \n",
      "1               0                 0                 0             0.0  \n",
      "2               1                 0                 0             0.0  \n",
      "3               0                 0                 0             0.0  \n",
      "4               0                 0                 0             0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "0        s1a-001\n",
      "1        s1a-001\n",
      "2        s1a-001\n",
      "3        s1a-001\n",
      "4        s1a-001\n",
      "          ...   \n",
      "77239    w2f-020\n",
      "77240    w2f-020\n",
      "77241    w2f-020\n",
      "77242    w2f-020\n",
      "77243    w2f-020\n",
      "Name: group, Length: 77244, dtype: object\n",
      "                                                      b id  word_S  \\\n",
      "group                                                                \n",
      "s1a-001  icesing_s1a-001_1_1icesing_s1a-001_1_2icesing_...  1939.0   \n",
      "s1a-002  icesing_s1a-002_1_1icesing_s1a-002_1_2icesing_...  1969.0   \n",
      "s1a-003  icesing_s1a-003_1_1icesing_s1a-003_1_2icesing_...  1936.0   \n",
      "s1a-004  icesing_s1a-004_1_1icesing_s1a-004_1_2icesing_...  1999.0   \n",
      "s1a-005  icesing_s1a-005_1_2icesing_s1a-005_1_3icesing_...  1939.0   \n",
      "...                                                    ...     ...   \n",
      "w2f-016  icesing_w2f-016_1_1_aicesing_w2f-016_1_2_aices...  2054.0   \n",
      "w2f-017  icesing_w2f-017_1_1_aicesing_w2f-017_1_2_aices...  2027.0   \n",
      "w2f-018  icesing_w2f-018_1_1_aicesing_w2f-018_1_2_aices...  2046.0   \n",
      "w2f-019  icesing_w2f-019_1_1_aicesing_w2f-019_1_2_aices...  2039.0   \n",
      "w2f-020  icesing_w2f-020_1_1_aicesing_w2f-020_1_2_aices...  2019.0   \n",
      "\n",
      "         lexical_density       nn_W       np_W  nominal_W  neoclass_W  \\\n",
      "group                                                                   \n",
      "s1a-001        88.618333  33.318585   4.105490   3.349878    0.247475   \n",
      "s1a-002       138.017368  45.851733  12.823748   7.018149    1.771368   \n",
      "s1a-003       124.975649  43.509770  13.976375   4.284408    0.608766   \n",
      "s1a-004       117.221861  33.895172   8.507669   2.853756    0.602778   \n",
      "s1a-005       144.796046  53.232122  15.264584   7.398164    0.628788   \n",
      "...                  ...        ...        ...        ...         ...   \n",
      "w2f-016        74.616761  25.252771   3.857249   5.981046    0.253892   \n",
      "w2f-017        70.829113  27.015213   4.328818   5.705696    0.453797   \n",
      "w2f-018        95.996580  40.004034   2.766301   4.015908    0.157576   \n",
      "w2f-019        72.807689  24.173161   3.263314   3.824762    0.168893   \n",
      "w2f-020        66.587457  25.914958   5.776936   3.808727    0.424679   \n",
      "\n",
      "         poss_pronoun_W  pronoun_all_W  p1_perspron_P  ...  time_adv_W  \\\n",
      "group                                                  ...               \n",
      "s1a-001        4.449120      28.961574      38.930952  ...    2.708864   \n",
      "s1a-002        3.268980      56.190331      48.416667  ...    3.543943   \n",
      "s1a-003        2.185212      42.788303      58.450000  ...    4.157288   \n",
      "s1a-004        3.498240      48.732113      60.400000  ...    3.928936   \n",
      "s1a-005        2.927070      39.660875      27.166667  ...    3.199759   \n",
      "...                 ...            ...            ...  ...         ...   \n",
      "w2f-016        4.281061      17.732463      10.392857  ...    1.190534   \n",
      "w2f-017        4.152697      21.193357      17.833333  ...    2.050702   \n",
      "w2f-018        7.537012      23.338745      10.500000  ...    1.403536   \n",
      "w2f-019        5.445134      31.669110      58.391667  ...    4.834148   \n",
      "w2f-020        3.523764      11.019463       1.250000  ...    1.437094   \n",
      "\n",
      "         nom_initial_S  prep_initial_S  adv_initial_S  text_initial_S  \\\n",
      "group                                                                   \n",
      "s1a-001           81.0              10           30.0              10   \n",
      "s1a-002          151.0               6           26.0              20   \n",
      "s1a-003          132.0               7           26.0              22   \n",
      "s1a-004          132.0               3           42.0              17   \n",
      "s1a-005          128.0              12           36.0              23   \n",
      "...                ...             ...            ...             ...   \n",
      "w2f-016           93.0               8           20.0               1   \n",
      "w2f-017           82.0              12           14.0               5   \n",
      "w2f-018          115.0              14            8.0               4   \n",
      "w2f-019           98.0               4           13.0              19   \n",
      "w2f-020           82.0               7           17.0               8   \n",
      "\n",
      "         wh_initial_S  disc_initial_S  nonfin_initial_S  subord_initial_S  \\\n",
      "group                                                                       \n",
      "s1a-001           9.0              20                 5                20   \n",
      "s1a-002          19.0              66                 6                17   \n",
      "s1a-003          13.0              48                15                19   \n",
      "s1a-004          21.0              25                 7                14   \n",
      "s1a-005          24.0              60                15                29   \n",
      "...               ...             ...               ...               ...   \n",
      "w2f-016           3.0               3                 8                12   \n",
      "w2f-017           6.0               4                 6                17   \n",
      "w2f-018           9.0               1                 2                 6   \n",
      "w2f-019           3.0               2                 4                 4   \n",
      "w2f-020           2.0               0                 1                 4   \n",
      "\n",
      "         verb_initial_S  \n",
      "group                    \n",
      "s1a-001            13.0  \n",
      "s1a-002            17.0  \n",
      "s1a-003            13.0  \n",
      "s1a-004            13.0  \n",
      "s1a-005            16.0  \n",
      "...                 ...  \n",
      "w2f-016             4.0  \n",
      "w2f-017             0.0  \n",
      "w2f-018            15.0  \n",
      "w2f-019            13.0  \n",
      "w2f-020             3.0  \n",
      "\n",
      "[495 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "df =pd.read_csv('updated_file.csv', delimiter=',')\n",
    "# Check for NaN or Inf values in the original data\n",
    "print(df.head())\n",
    "\n",
    "df['group'] = df['b id'].str.split('_').str[1]\n",
    "print(df['group'])\n",
    "                    \n",
    "# Group by the base ID and s                               um over the columns (excluding 'id' and 'group')\n",
    "grouped_sum = df.groupby('group').sum()\n",
    "print(grouped_sum)\n",
    "grouped_sum.to_csv('Summed_new_features.csv', index='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           n_token  n_sent  n_word    ld   nn  np  nom  neo  poss  pronoun  \\\n",
      "group                                                                        \n",
      "s1a-001_1     1939     209    1939   811  269  33   32    4    29      293   \n",
      "s1a-002_1     1969     334    1969   843  270  49   35    9    26      352   \n",
      "s1a-003_1     1936     291    1936   849  279  71   30    5    14      302   \n",
      "s1a-004_1     1999     283    1999   846  256  36   30    5    34      350   \n",
      "s1a-005_1     1939     353    1939   823  280  51   48    4    20      249   \n",
      "...            ...     ...     ...   ...  ...  ..  ...  ...   ...      ...   \n",
      "w2f-017_1     1455      79    1286   627  266   8   61    6    36      168   \n",
      "w2f-017_2      909      63     741   356  121  36   21    2    31      123   \n",
      "w2f-018_1     2454     178    2046  1051  445  33   49    3    86      247   \n",
      "w2f-019_1     2375     162    2039   909  354  20   55    4    78      345   \n",
      "w2f-020_1     2262     125    2019  1045  425  75   73    5    57      171   \n",
      "\n",
      "           ...  time_adv_W  nom_initial_S  prep_initial_S  adv_initial_S  \\\n",
      "group      ...                                                             \n",
      "s1a-001_1  ...    2.708864           81.0            10.0           30.0   \n",
      "s1a-002_1  ...    3.543943          151.0             6.0           26.0   \n",
      "s1a-003_1  ...    4.157288          132.0             7.0           26.0   \n",
      "s1a-004_1  ...    3.928936          132.0             3.0           42.0   \n",
      "s1a-005_1  ...    3.199759          128.0            12.0           36.0   \n",
      "...        ...         ...            ...             ...            ...   \n",
      "w2f-017_1  ...    0.716856           47.0             8.0            4.0   \n",
      "w2f-017_2  ...    1.333846           35.0             4.0           10.0   \n",
      "w2f-018_1  ...    1.403536          115.0            14.0            8.0   \n",
      "w2f-019_1  ...    4.834148           98.0             4.0           13.0   \n",
      "w2f-020_1  ...    1.437094           82.0             7.0           17.0   \n",
      "\n",
      "           text_initial_S  wh_initial_S  disc_initial_S  nonfin_initial_S  \\\n",
      "group                                                                       \n",
      "s1a-001_1            10.0           9.0            20.0               5.0   \n",
      "s1a-002_1            20.0          19.0            66.0               6.0   \n",
      "s1a-003_1            22.0          13.0            48.0              15.0   \n",
      "s1a-004_1            17.0          21.0            25.0               7.0   \n",
      "s1a-005_1            23.0          24.0            60.0              15.0   \n",
      "...                   ...           ...             ...               ...   \n",
      "w2f-017_1             2.0           4.0             0.0               5.0   \n",
      "w2f-017_2             3.0           2.0             4.0               1.0   \n",
      "w2f-018_1             4.0           9.0             1.0               2.0   \n",
      "w2f-019_1            19.0           3.0             2.0               4.0   \n",
      "w2f-020_1             8.0           2.0             0.0               1.0   \n",
      "\n",
      "           subord_initial_S  verb_initial_S  \n",
      "group                                        \n",
      "s1a-001_1              20.0            13.0  \n",
      "s1a-002_1              17.0            17.0  \n",
      "s1a-003_1              19.0            13.0  \n",
      "s1a-004_1              14.0            13.0  \n",
      "s1a-005_1              29.0            16.0  \n",
      "...                     ...             ...  \n",
      "w2f-017_1              13.0             0.0  \n",
      "w2f-017_2               4.0             0.0  \n",
      "w2f-018_1               6.0            15.0  \n",
      "w2f-019_1               4.0            13.0  \n",
      "w2f-020_1               4.0             3.0  \n",
      "\n",
      "[931 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('updated_file.csv', delimiter=',')\n",
    "\n",
    "# Extract the general base ID (e.g., 's1a-XXX', 's2b-YYY', etc.)\n",
    "df['base_id'] = df['b id'].str.extract(r'([a-zA-Z0-9]+-\\d+)')  # Match any prefix followed by a hyphen and digits\n",
    "\n",
    "# Extract the sub-group number (e.g., '_X')\n",
    "df['sub_group'] = df['b id'].str.extract(r'_(\\d+)_')  # Extract the `_X` portion as a number\n",
    "\n",
    "# Create a combined group identifier\n",
    "df['group'] = df['base_id'] + '_' + df['sub_group']\n",
    "\n",
    "# Group by the combined group ID and sum over numeric columns\n",
    "grouped_sum = df.groupby('group').sum(numeric_only=True)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "grouped_sum.to_csv('summed_document_generalized.csv', index=True)\n",
    "\n",
    "# Print the resulting groups for verification\n",
    "print(grouped_sum)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial DataFrame:\n",
      "     group                                                 id  n_token  \\\n",
      "0  s1a-001  icesing_s1a-001_1_1icesing_s1a-001_1_2icesing_...     1939   \n",
      "1  s1a-002  icesing_s1a-002_1_1icesing_s1a-002_1_2icesing_...     1969   \n",
      "2  s1a-003  icesing_s1a-003_1_1icesing_s1a-003_1_2icesing_...     1936   \n",
      "3  s1a-004  icesing_s1a-004_1_1icesing_s1a-004_1_2icesing_...     1999   \n",
      "4  s1a-005  icesing_s1a-005_1_2icesing_s1a-005_1_3icesing_...     1939   \n",
      "\n",
      "   n_sent  n_word   ld   nn  np  nom  neo  ...  numbertheme  pptheme  \\\n",
      "0     209    1939  811  269  33   32    4  ...            9       10   \n",
      "1     334    1969  843  270  49   35    9  ...            2        6   \n",
      "2     291    1936  849  279  71   30    5  ...            7        7   \n",
      "3     283    1999  846  256  36   30    5  ...           11        3   \n",
      "4     353    1939  823  280  51   48    4  ...           19       12   \n",
      "\n",
      "   advtheme  cctheme  whtheme  disctheme  totheme  cstheme  subordtheme  \\\n",
      "0        30       10        9         20        5       15           20   \n",
      "1        26       20       19         66        6       11           17   \n",
      "2        26       22       13         48       15        4           19   \n",
      "3        42       17       21         25        7        7           14   \n",
      "4        36       23       24         60       15       14           29   \n",
      "\n",
      "   verbtheme  \n",
      "0         13  \n",
      "1         17  \n",
      "2         13  \n",
      "3         13  \n",
      "4         16  \n",
      "\n",
      "[5 rows x 48 columns]\n",
      "Index(['group', 'id', 'n_token', 'n_sent', 'n_word', 'ld', 'nn', 'np', 'nom',\n",
      "       'neo', 'poss', 'pronoun', 'p1', 'p2', 'p3', 'pit', 'pospers1',\n",
      "       'pospers2', 'pospers3', 'adj', 'atadj', 'prep', 'fin', 'past', 'will',\n",
      "       'vm', 'v', 'inf', 'pass', 'coord', 'subord', 'interr', 'imper', 'title',\n",
      "       'salutgreet', 'rl', 'rt', 'nptheme', 'numbertheme', 'pptheme',\n",
      "       'advtheme', 'cctheme', 'whtheme', 'disctheme', 'totheme', 'cstheme',\n",
      "       'subordtheme', 'verbtheme'],\n",
      "      dtype='object')\n",
      "Normalized data saved to normalized_TEXTS.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Summed.csv', delimiter=';')\n",
    "\n",
    "# Print basic info for debugging\n",
    "print(\"Initial DataFrame:\")\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "\n",
    "# Step 1: Identify all numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Step 2: Normalize all numeric columns by 'n_token'\n",
    "for col in numeric_columns:\n",
    "    # Divide each column by its row's 'n_token' value\n",
    "    df[col] = df[col] / df['n_token']\n",
    "\n",
    "# Step 3: After normalization, set the 'n_token' column values to 1\n",
    "df['n_token'] = 1\n",
    "\n",
    "# Step 4: Save the normalized DataFrame to a new CSV file\n",
    "output_file = 'normalized_TEXTS.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Normalized data saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
